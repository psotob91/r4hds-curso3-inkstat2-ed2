[
  {
    "objectID": "assignment/index.html",
    "href": "assignment/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Los objetivos de este curso es que ustedes puedan realizar un análisis descriptivo y, cuando sea apropiado, aplicar métodos de inferencia estadístico. Cada tarea está diseñada para ayudarles a alcanzar una de estas metas."
  },
  {
    "objectID": "assignment/index.html#problem-sets",
    "href": "assignment/index.html#problem-sets",
    "title": "Tareas",
    "section": "Problem sets",
    "text": "Problem sets\nPara paracticar escribir código en R, realizar análisis descriptivos y aplicar inferencia estadística, completará una serie de conjunto de problemas o Problem sets.\nDeberá demostrar que hizo un esfuerzo consciente para resolver cada pregunta.\n\n✔+: (20 puntos) La tarea está 100% completa. Todas las preguntas fueron respondidas, y la mayoría de las respuestas son correctas. El documento es limpio y fácil de seguir. El trabajo es excepcional. A menudo no asignaré este puntaje.\n✔: (18 puntos) La tarea está completa en un 70–99 % y la mayoría de las respuestas son correctas. Este es el nivel de rendimiento esperado.\n✔−: (13 puntos) La tarea está completa en menos del 70 % y/o la mayoría de las respuestas son incorrectas. Esto indica que necesita mejorar la próxima vez. Espero no asignarlos a menudo.\n\nPueden (¡y deben!) trabajar juntos en los conjuntos de problemas, pero deben entregar sus propias respuestas. No pueden trabajar en grupos de más de cuatro personas, y deben indicar quién participó en el grupo en tu tarea"
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Introducción a R y RStudio",
    "section": "",
    "text": "¡Bienvenidos al curso R para Ciencia de Datos en Salud:Análisis Descriptivo e Inferencia Estadística!\n\n\n\n\n\n\nObjetivos\n\n\n\nEn esta primera sesión revisaremos los siguiente:\n\nExplicación de la dinámica del curso.\nCiencia de Datos en Salud Reproducible.\n¿Qué es R y RStudio? ¿Cuáles son las principales herramientas con las que cuenta?\nPrimeros pasos con R\nManejo y visualización de datos\n\n\n\n\n\nAntes que todo, debe instalar la última versión de los programas que usaremos para este curso. Dependiendo su sistema operativo, Ud. debería instalar los siguientes programas:\n\nWindowsMacLinux (cualquier distro)\n\n\n\nR\nR Studio\nR tools\n\n\n\n\nR\nR Studio\n\n\n\n\nR\nR Studio\n\n\n\n\nSi cuenta con una versión previa, elimínelas y reinstale todo de nuevo: debe tener la última versión actualizada de todos estos. Si nunca ha instalado R, ni los demás programa, hemos preparado el siguiente tutorial de instalación, el cual está disponible en la sección Recursos de la web del curso: Enlace aquí.\nSi tiene alguna duda durante la instalación, no dude en escribir por el Whatssap grupo o por el Discord del grupo."
  },
  {
    "objectID": "content/01-content.html#introducción-al-curso",
    "href": "content/01-content.html#introducción-al-curso",
    "title": "Introducción a R y RStudio",
    "section": "Introducción al curso",
    "text": "Introducción al curso\n\nBievenidaCómo usar la web del cursoCómo descargar los slides\n\n\n\n\n\n\n\n\n\nAcceda a la web del curso: https://rcds3.inkastats.es/\n\n\n\n\n\n\n\nComo las diapositivas son interactivas, optamos por guardarlas como HTML (no como PDF). Puedes descargar la diapositiva con la opción Guardar como al dar click derecho sobre esta."
  },
  {
    "objectID": "content/01-content.html#videoclases",
    "href": "content/01-content.html#videoclases",
    "title": "Introducción a R y RStudio",
    "section": "Videoclases",
    "text": "Videoclases\n\nIntroducción a R y RstudioPrimeros pasosDatos en RVisualización de datosManejo de datos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuestro turno: Mi primer proyecto\n\n\n\n\nPuede descargar los archivos generados en la carpeta mi_primer_proyecto en el siguiente enlace: Aquí.\nPuede ver la versión Web de este ejercicio en el siguiente enlace se la sección Ejemplos: Aquí\n\n\n\n\n\n\n\n\n\n¿Cómo abrir proyecto existente?\n\n\n\nCuando quiera iniciar un proyecto existente de R, recuerde abrirlo a través del archivo del proyecto (extensión *.Rproj).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuestro turno: Importar datos\n\n\n\n\nPuede descargar los archivos generados en la carpeta importar_datos en el siguiente enlace: Aquí.\nPuede ver la versión Web de este ejercicio en el siguiente enlace se la sección Ejemplos: Aquí\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuestro turno: Mi primer y segundo ggplot\n\n\n\n\nPuede descargar los archivos generados en la carpeta mi_primer_ggplot en el siguiente enlace: Aquí.\nPuede ver la versión Web de este ejercicio en el siguiente enlace se la sección Ejemplos: Aquí\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuestro turno: Mi primer manejo de datos\n\n\n\n\nPuede descargar los archivos generados en la carpeta mi_primer_manejo_datos en el siguiente enlace: Aquí.\nPuede ver la versión Web de este ejercicio en el siguiente enlace se la sección Ejemplos: Aquí"
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Introducción a R y RStudio",
    "section": "Slides",
    "text": "Slides\n\nBievenidaIntroducción a R y RstudioPrimeros pasosDatos en RVisualización de datosManejo de datos\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana"
  },
  {
    "objectID": "content/02-content.html",
    "href": "content/02-content.html",
    "title": "Análisis descriptivo univariado",
    "section": "",
    "text": "Objetivos\n\n\n\nEn esta segunda sesión revisaremos los siguiente:\n\nDescripción univariada de datos numéricos\nDescripción univariadade datos categóricos\nDescripción univariada de datos de tiempos de supervivencia\nRevisión de recomendaciones de guías de reporte sobre descripción de datos"
  },
  {
    "objectID": "content/02-content.html#videoclases",
    "href": "content/02-content.html#videoclases",
    "title": "Análisis descriptivo univariado",
    "section": "Videoclases",
    "text": "Videoclases\n\nTipo de variablesDatos numéricosEvaluación de distribuciónDatos categóricosDatos de tiempo de supervivenciaRevisando guías de reporte"
  },
  {
    "objectID": "content/02-content.html#slides",
    "href": "content/02-content.html#slides",
    "title": "Análisis descriptivo univariado",
    "section": "Slides",
    "text": "Slides\n\nTipo de variablesDatos numéricosEvaluación de distribuciónDatos categóricosDatos de tiempo de supervivenciaRevisando guías de reporte\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Análisis descriptivo bivariado",
    "section": "",
    "text": "Objetivos\n\n\n\nEn esta tercera sesión revisaremos los siguiente:\n\nAnálisis bivariado\nComparación de variables numéricos entre grupos\nComparación de variables categóricas entre grupos\nComparación de variables de tiempo de supervencia entre grupos\nCorrelación de variables numéricas"
  },
  {
    "objectID": "content/03-content.html#videoclases",
    "href": "content/03-content.html#videoclases",
    "title": "Análisis descriptivo bivariado",
    "section": "Videoclases",
    "text": "Videoclases\n\nAnálisis bivariadoComparación de grupos: Desenlace numéricoComparación de grupos: Desenlace categóricoComparación de grupos: Desenlace tiempo de supervivenciaCorrelación de variables numéricas"
  },
  {
    "objectID": "content/03-content.html#slides",
    "href": "content/03-content.html#slides",
    "title": "Análisis descriptivo bivariado",
    "section": "Slides",
    "text": "Slides\n\nAnálisis bivariadoComparación de grupos: Desenlace numéricoComparación de grupos: Desenlace categóricoComparación de grupos: Desenlace tiempo de supervivenciaCorrelación de variables numéricas\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana"
  },
  {
    "objectID": "content/04-content.html",
    "href": "content/04-content.html",
    "title": "Reporte descriptivo reproducible",
    "section": "",
    "text": "Objetivos\n\n\n\nEn esta cuarta sesión revisaremos los siguiente:\n\nDocumentos Markdown, R markdown y Quarto.\nGeneración de documentos en html.\nGeneración de documentos de texto.\nGeneración de documentos en PDF.\nGeneración de tablas reproducibles y automatizadas.\nBuenas prácticas de ciencia reproducible."
  },
  {
    "objectID": "content/04-content.html#videoclases",
    "href": "content/04-content.html#videoclases",
    "title": "Reporte descriptivo reproducible",
    "section": "Videoclases",
    "text": "Videoclases\n\nMarkdown, R Markdown y QuartoHTMLWordPDFTablas reproduciblesBuenas Prácticas"
  },
  {
    "objectID": "content/04-content.html#slides",
    "href": "content/04-content.html#slides",
    "title": "Reporte descriptivo reproducible",
    "section": "Slides",
    "text": "Slides\n\nMarkdown, R Markdown y QuartoHTMLWordPDFTablas reproduciblesBuenas Prácticas\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana\n\n\n\n\n\n\n\n\n Ver diapositivas en una nueva ventana"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Clases, lecturas y videos",
    "section": "",
    "text": "Ver diapositivas en una nueva ventana\nLas diapositivas también están incrustadas en cada página. Puede hacer clic en las diapositivas y navegar por ellas con ← and →. Si escribe ? mientras ve las diapositivas, puede ver una lista de comandos específicos de diapositivas (como f para pantalla completa).\nPor último, cada sesión de clase tiene un conjunto de lecturas recomendadas que se sugiere revisen para afianzar o ampliar lo abordado en clases."
  },
  {
    "objectID": "example/importar_datos/importar_datos_ejemplos.html",
    "href": "example/importar_datos/importar_datos_ejemplos.html",
    "title": "Importando Datos con R - Ejemplos",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(rio)\nlibrary(haven)"
  },
  {
    "objectID": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.csv-archivo-plano",
    "href": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.csv-archivo-plano",
    "title": "Importando Datos con R - Ejemplos",
    "section": "Importar datos en *.csv (archivo plano)",
    "text": "Importar datos en *.csv (archivo plano)\nImporte el archivo denominado maca_meno_perclin.csv:\n\n\nCódigo\ndatos_csv <- import(\"maca_meno_perclin.csv\")\n\n\nExplore el data.frame importado:\n\n\nCódigo\nhead(datos_csv)\n\n\n  id_jaula id_raton tratamiento protocolo peso_inicial peso_final peso_utero\n1        1        1     control       ovx        26.00      33.28      0.089\n2        1        2     control       ovx        24.50      30.50      0.063\n3        1        3     control       ovx        20.40      29.93      0.078\n4        2        4     control   hemiovx        26.59      32.19      0.134\n5        2        5     control       ovx        23.50      30.37      0.052\n6        2        6        maca       ovx        25.00      30.43      0.055\n    chol glucose    tag prot  urea album\n1  85.99  109.97 182.42 5.37 66.27 66.82\n2  94.46   81.62 211.87 4.68 76.73 55.36\n3  99.67  118.37 195.16   NA 52.32    NA\n4  83.38   71.91  98.46   NA 50.71    NA\n5  82.08   95.53 108.13 5.33 26.02    NA\n6 107.49  160.36 141.10   NA    NA 72.14"
  },
  {
    "objectID": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.xlsx-ms-excel",
    "href": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.xlsx-ms-excel",
    "title": "Importando Datos con R - Ejemplos",
    "section": "Importar datos en *.xlsx (MS Excel)",
    "text": "Importar datos en *.xlsx (MS Excel)\nImporte el archivo denominado maca_meno_perclin.xlsx:\n\n\nCódigo\ndatos_xslx <- import(\"maca_meno_perclin.xlsx\")\n\n\nExplore el data.frame importado:\n\n\nCódigo\nglimpse(datos_xslx)\n\n\nRows: 23\nColumns: 13\n$ id_jaula     <dbl> 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 5, 5, 5, 5, 8, 8, 9, 9, 9, …\n$ id_raton     <dbl> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ tratamiento  <chr> \"control\", \"control\", \"control\", \"control\", \"control\", \"m…\n$ protocolo    <chr> \"ovx\", \"ovx\", \"ovx\", \"hemiovx\", \"ovx\", \"ovx\", \"ovx\", \"ovx…\n$ peso_inicial <dbl> 26.00, 24.50, 20.40, 26.59, 23.50, 25.00, 24.80, 23.20, 2…\n$ peso_final   <dbl> 33.28, 30.50, 29.93, 32.19, 30.37, 30.43, 28.77, 27.30, 2…\n$ peso_utero   <dbl> 0.089, 0.063, 0.078, 0.134, 0.052, 0.055, 0.064, 0.062, 0…\n$ chol         <dbl> 85.990, 94.460, 99.670, 83.380, 82.080, 107.490, 76.870, …\n$ glucose      <dbl> 109.97, 81.62, 118.37, 71.91, 95.53, 160.36, 195.53, 182.…\n$ tag          <dbl> 182.42, 211.87, 195.16, 98.46, 108.13, 141.10, 95.82, 105…\n$ prot         <dbl> 5.37, 4.68, NA, NA, 5.33, NA, 5.02, 6.12, NA, 4.85, NA, N…\n$ urea         <dbl> 66.27, 76.73, 52.32, 50.71, 26.02, NA, 40.78, 66.94, NA, …\n$ album        <dbl> 66.82, 55.36, NA, NA, NA, 72.14, 67.09, 70.64, 66.27, 83.…"
  },
  {
    "objectID": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.dta-stata",
    "href": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.dta-stata",
    "title": "Importando Datos con R - Ejemplos",
    "section": "Importar datos en *.dta (Stata)",
    "text": "Importar datos en *.dta (Stata)\nImporte el archivo denominado maca_meno_fase1.dta:\n\nOpción 1: Usar import\n\n\n\nCódigo\ndatos_stata1 <- import(\"maca_meno_fase1.dta\")\n\n\nExplore el data.frame importado:\n\n\nCódigo\nglimpse(datos_stata1)\n\n\nRows: 106\nColumns: 14\n$ id         <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 1…\n$ time       <dbl> 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,…\n$ treat      <dbl> 1, 1, 3, 3, 2, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 3, 3, 1, 1,…\n$ age        <dbl> 33, 32, 27, 27, 25, 25, 37, 38, 31, 32, 38, 38, 26, 26, 34,…\n$ race       <chr> \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mes…\n$ married    <dbl> 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1,…\n$ married2   <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,…\n$ procedence <chr> \"Callao\", \"Callao\", \"Santa Anita\", \"Santa Anita\", \"Callao\",…\n$ weight     <dbl> 59.0, 59.9, 62.0, 62.1, 62.0, 60.0, 60.9, 61.4, 64.0, 58.1,…\n$ height     <dbl> 1.4, 1.3, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.6, 1.5, 1.5,…\n$ e2         <dbl> 87.30, 210.05, 169.01, 99.91, 78.76, 155.04, 40.99, 109.03,…\n$ lh         <dbl> 3.28, 26.85, 6.34, 5.77, 11.86, 10.14, 4.57, 7.29, 7.81, 9.…\n$ fsh        <dbl> 1.95, 8.83, 4.32, 1.70, 2.81, 4.51, 3.81, 2.39, 2.01, 3.66,…\n$ prog       <dbl> 14.20, 12.95, 0.50, 9.61, 10.46, 5.04, 4.64, 11.73, 15.11, …\n\n\n\nOpción 2: Usar read_stata de {haven} y as_factor()\n\n\n\nCódigo\ndatos_stata2 <- as_factor(read_stata(\"maca_meno_fase1.dta\"))\n\n\nExplore el data.frame importado:\n\n\nCódigo\nglimpse(datos_stata2)\n\n\nRows: 106\nColumns: 14\n$ id         <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 1…\n$ time       <fct> Baseline, 3 months, Baseline, 3 months, Baseline, 3 months,…\n$ treat      <fct> PLACEBO, PLACEBO, WARMI 6 C/D, WARMI 6 C/D, WARMI 3 C/D, WA…\n$ age        <dbl> 33, 32, 27, 27, 25, 25, 37, 38, 31, 32, 38, 38, 26, 26, 34,…\n$ race       <chr> \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mes…\n$ married    <fct> Single, Single, Single, Single, Single, Single, Divorced, D…\n$ married2   <fct> Without couple, Without couple, Without couple, Without cou…\n$ procedence <chr> \"Callao\", \"Callao\", \"Santa Anita\", \"Santa Anita\", \"Callao\",…\n$ weight     <dbl> 59.0, 59.9, 62.0, 62.1, 62.0, 60.0, 60.9, 61.4, 64.0, 58.1,…\n$ height     <dbl> 1.4, 1.3, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.6, 1.5, 1.5,…\n$ e2         <dbl> 87.30, 210.05, 169.01, 99.91, 78.76, 155.04, 40.99, 109.03,…\n$ lh         <dbl> 3.28, 26.85, 6.34, 5.77, 11.86, 10.14, 4.57, 7.29, 7.81, 9.…\n$ fsh        <dbl> 1.95, 8.83, 4.32, 1.70, 2.81, 4.51, 3.81, 2.39, 2.01, 3.66,…\n$ prog       <dbl> 14.20, 12.95, 0.50, 9.61, 10.46, 5.04, 4.64, 11.73, 15.11, …"
  },
  {
    "objectID": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.sav-spss",
    "href": "example/importar_datos/importar_datos_ejemplos.html#importar-datos-en-.sav-spss",
    "title": "Importando Datos con R - Ejemplos",
    "section": "Importar datos en *.sav (SPSS)",
    "text": "Importar datos en *.sav (SPSS)\n\nOpción 1:\n\nImporte el archivo denominado RECH0.SAV:\n\n\nCódigo\ndatos_spss <- import(\"RECH0.SAV\")\n\n\nExplore el data.frame importado:\n\n\nCódigo\nglimpse(datos_spss)\n\n\nRows: 37,479\nColumns: 44\n$ ID1       <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ HHID      <chr> \"      000100301\", \"      000100401\", \"      000100801\", \"  …\n$ HV000     <chr> \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6…\n$ HV001     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV002     <dbl> 3, 4, 8, 10, 29, 42, 62, 70, 73, 95, 1, 32, 39, 54, 56, 59, …\n$ HV002A    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV003     <dbl> 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 2, 1, …\n$ HV004     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV007     <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ HV008     <dbl> 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, …\n$ HV009     <dbl> 6, 5, 6, 5, 0, 3, 3, 3, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV010     <dbl> 2, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 1, …\n$ HV011     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV012     <dbl> 6, 5, 6, 5, 0, 3, 3, 3, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV013     <dbl> 5, 5, 6, 5, 0, 3, 3, 2, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV014     <dbl> 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, …\n$ HV015     <dbl> 1, 1, 1, 1, 3, 1, 1, 1, 6, 2, 6, 5, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV017     <dbl> 1, 1, 1, 1, 4, 1, 1, 1, 4, 2, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV020     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV021     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV023     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV024     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV025     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV026     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV027     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV028     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV030     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV031     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV032     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV033     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV035     <dbl> 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, …\n$ HV040     <dbl> 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, …\n$ HV041     <dbl> 2, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 1, …\n$ HV042     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV043     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV044     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ UBIGEO    <chr> \"010101\", \"010101\", \"010101\", \"010101\", \"010101\", \"010101\", …\n$ HV022     <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ CODCCPP   <chr> \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"000…\n$ NOMCCPP   <chr> \"CHACHAPOYAS\", \"CHACHAPOYAS\", \"CHACHAPOYAS\", \"CHACHAPOYAS\", …\n$ NCONGLOME <chr> \"0706402\", \"0706402\", \"0706402\", \"0706402\", \"0706402\", \"0706…\n$ HV005     <dbl> 103273, 103273, 103273, 532968, 0, 103273, 532968, 103273, 0…\n$ longitudx <dbl> -77.87403, -77.87403, -77.87403, -77.87403, -77.87403, -77.8…\n$ latitudy  <dbl> -6.221249, -6.221249, -6.221249, -6.221249, -6.221249, -6.22…\n\n\n\nOpción 2:\n\nImporte el archivo denominado RECH0.SAV usando read_sav de {haven}y as_factor\n\n\nCódigo\ndatos_spss2 <- as_factor(read_sav(\"RECH0.SAV\"))\n\n\nExplore el data.frame importado:\n\n\nCódigo\nglimpse(datos_spss2)\n\n\nRows: 37,479\nColumns: 44\n$ ID1       <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ HHID      <chr> \"      000100301\", \"      000100401\", \"      000100801\", \"  …\n$ HV000     <chr> \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6\", \"PE6…\n$ HV001     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV002     <dbl> 3, 4, 8, 10, 29, 42, 62, 70, 73, 95, 1, 32, 39, 54, 56, 59, …\n$ HV002A    <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV003     <dbl> 2, 1, 2, 1, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 3, 3, 3, 2, 1, …\n$ HV004     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV007     <dbl> 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, …\n$ HV008     <dbl> 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, 1454, …\n$ HV009     <dbl> 6, 5, 6, 5, 0, 3, 3, 3, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV010     <dbl> 2, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 1, …\n$ HV011     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV012     <dbl> 6, 5, 6, 5, 0, 3, 3, 3, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV013     <dbl> 5, 5, 6, 5, 0, 3, 3, 2, 0, 0, 0, 0, 3, 5, 4, 4, 6, 5, 4, 3, …\n$ HV014     <dbl> 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, …\n$ HV015     <fct> Completo, Completo, Completo, Completo, Hogar ausente, Compl…\n$ HV017     <dbl> 1, 1, 1, 1, 4, 1, 1, 1, 4, 2, 3, 5, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ HV020     <fct> Muestra todas las mujeres, Muestra todas las mujeres, Muestr…\n$ HV021     <dbl> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, …\n$ HV023     <fct> Amazonas, Amazonas, Amazonas, Amazonas, Amazonas, Amazonas, …\n$ HV024     <fct> Amazonas, Amazonas, Amazonas, Amazonas, Amazonas, Amazonas, …\n$ HV025     <fct> Urbano, Urbano, Urbano, Urbano, Urbano, Urbano, Urbano, Urba…\n$ HV026     <fct> \"Pequeña ciudad\", \"Pequeña ciudad\", \"Pequeña ciudad\", \"Peque…\n$ HV027     <fct> No seleccionado, No seleccionado, No seleccionado, No selecc…\n$ HV028     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV030     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV031     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV032     <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ HV033     <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ HV035     <dbl> 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, …\n$ HV040     <dbl> 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, 2338, …\n$ HV041     <dbl> 2, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 2, 1, 0, 2, 0, 1, 1, …\n$ HV042     <fct> Seleccionado, Seleccionado, Seleccionado, Seleccionado, Sele…\n$ HV043     <fct> Hogar no seleccionado, Hogar no seleccionado, Hogar no selec…\n$ HV044     <fct> Hogar seleccionado, Hogar seleccionado, Hogar seleccionado, …\n$ UBIGEO    <chr> \"010101\", \"010101\", \"010101\", \"010101\", \"010101\", \"010101\", …\n$ HV022     <dbl> 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ CODCCPP   <chr> \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"0001\", \"000…\n$ NOMCCPP   <chr> \"CHACHAPOYAS\", \"CHACHAPOYAS\", \"CHACHAPOYAS\", \"CHACHAPOYAS\", …\n$ NCONGLOME <chr> \"0706402\", \"0706402\", \"0706402\", \"0706402\", \"0706402\", \"0706…\n$ HV005     <dbl> 103273, 103273, 103273, 532968, 0, 103273, 532968, 103273, 0…\n$ longitudx <dbl> -77.87403, -77.87403, -77.87403, -77.87403, -77.87403, -77.8…\n$ latitudy  <dbl> -6.221249, -6.221249, -6.221249, -6.221249, -6.221249, -6.22…"
  },
  {
    "objectID": "example/index.html",
    "href": "example/index.html",
    "title": "Ejemplos de código",
    "section": "",
    "text": "Venga a esta sección después de terminar de revisar las videoclases y lecturas. Contiene código en R completamente comentado y alguna que otra información complementaria. Será de mucha ayuda para resolver los problem set. También será de ayuda como plantillas que ustedes pueden reusar directamente o adaptar para futuros análisis de datos que realicen."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html",
    "title": "Mi primer ggplot",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(haven)\nlibrary(rio)\nlibrary(ggplot2)"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#importar-datos",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#importar-datos",
    "title": "Mi primer ggplot",
    "section": "Importar datos",
    "text": "Importar datos\n\n\nCódigo\ndatos <- as_factor(read_stata(\"maca_meno_fase1.dta\"))"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#inspeccionar-datos",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#inspeccionar-datos",
    "title": "Mi primer ggplot",
    "section": "Inspeccionar datos",
    "text": "Inspeccionar datos"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "title": "Mi primer ggplot",
    "section": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).",
    "text": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#cree-otro-gráfico-que-relacione-estradiol-e2-como-y-con-tratamiento-recibido-treat-como-x.-use-gráfico-de-puntos.-tip-use-geomtría-geom_point.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#cree-otro-gráfico-que-relacione-estradiol-e2-como-y-con-tratamiento-recibido-treat-como-x.-use-gráfico-de-puntos.-tip-use-geomtría-geom_point.",
    "title": "Mi primer ggplot",
    "section": "Cree otro gráfico que relacione estradiol (e2 como y) con tratamiento recibido (treat como x). Use gráfico de puntos. Tip: use geomtría geom_point().",
    "text": "Cree otro gráfico que relacione estradiol (e2 como y) con tratamiento recibido (treat como x). Use gráfico de puntos. Tip: use geomtría geom_point()."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#guarde-este-gráfico-como-un-objeto-pongale-de-nombre-plot1.-tip-use-operador-asignar--.-imprima-plot1",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#guarde-este-gráfico-como-un-objeto-pongale-de-nombre-plot1.-tip-use-operador-asignar--.-imprima-plot1",
    "title": "Mi primer ggplot",
    "section": "Guarde este gráfico como un objeto, pongale de nombre: plot1. Tip: Use operador asignar <-. Imprima plot1",
    "text": "Guarde este gráfico como un objeto, pongale de nombre: plot1. Tip: Use operador asignar <-. Imprima plot1"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#agregue-una-geometría-de-gráfico-de-cajas.-tip-agregue-geom_boxplot.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#agregue-una-geometría-de-gráfico-de-cajas.-tip-agregue-geom_boxplot.",
    "title": "Mi primer ggplot",
    "section": "Agregue una geometría de gráfico de cajas. Tip: Agregue geom_boxplot().",
    "text": "Agregue una geometría de gráfico de cajas. Tip: Agregue geom_boxplot().\n\nOpción 1: Ampliar el código usando geometrías:\n\n\n\n\n\nOpción 2: Reutilizar el objeto ggplot:"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot.html#invierta-el-orden-de-las-geometrías.-primero-ponga-geom_boxplot-y-luego-ponga-geom_point.-compare-con-el-gráfico-anterior.-en-qué-se-diferencian",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot.html#invierta-el-orden-de-las-geometrías.-primero-ponga-geom_boxplot-y-luego-ponga-geom_point.-compare-con-el-gráfico-anterior.-en-qué-se-diferencian",
    "title": "Mi primer ggplot",
    "section": "Invierta el orden de las geometrías. Primero ponga geom_boxplot() y luego ponga geom_point(). Compare con el gráfico anterior. ¿En qué se diferencian?",
    "text": "Invierta el orden de las geometrías. Primero ponga geom_boxplot() y luego ponga geom_point(). Compare con el gráfico anterior. ¿En qué se diferencian?"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html",
    "title": "Mi primer ggplot",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(haven)\nlibrary(rio)\nlibrary(ggplot2)"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#importar-datos",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#importar-datos",
    "title": "Mi primer ggplot",
    "section": "Importar datos",
    "text": "Importar datos\n\n\nCódigo\ndatos <- as_factor(read_stata(\"maca_meno_fase1.dta\"))"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#inspeccionar-datos",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#inspeccionar-datos",
    "title": "Mi primer ggplot",
    "section": "Inspeccionar datos",
    "text": "Inspeccionar datos\n\n\nCódigo\nglimpse(datos)\n\n\nRows: 106\nColumns: 14\n$ id         <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 1…\n$ time       <fct> Baseline, 3 months, Baseline, 3 months, Baseline, 3 months,…\n$ treat      <fct> Placebo, Placebo, Dosis 2, Dosis 2, Dosis 1, Dosis 1, Dosis…\n$ age        <dbl> 33, 32, 27, 27, 25, 25, 37, 38, 31, 32, 38, 38, 26, 26, 34,…\n$ race       <chr> \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mes…\n$ married    <fct> Single, Single, Single, Single, Single, Single, Divorced, D…\n$ married2   <fct> Without couple, Without couple, Without couple, Without cou…\n$ procedence <chr> \"Callao\", \"Callao\", \"Santa Anita\", \"Santa Anita\", \"Callao\",…\n$ weight     <dbl> 59.0, 59.9, 62.0, 62.1, 62.0, 60.0, 60.9, 61.4, 64.0, 58.1,…\n$ height     <dbl> 1.4, 1.3, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.6, 1.5, 1.5,…\n$ e2         <dbl> 87.30, 210.05, 169.01, 99.91, 78.76, 155.04, 40.99, 109.03,…\n$ lh         <dbl> 3.28, 26.85, 6.34, 5.77, 11.86, 10.14, 4.57, 7.29, 7.81, 9.…\n$ fsh        <dbl> 1.95, 8.83, 4.32, 1.70, 2.81, 4.51, 3.81, 2.39, 2.01, 3.66,…\n$ prog       <dbl> 14.20, 12.95, 0.50, 9.61, 10.46, 5.04, 4.64, 11.73, 15.11, …"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "title": "Mi primer ggplot",
    "section": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).",
    "text": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = fsh)) + \n  geom_point()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#cree-otro-gráfico-que-relacione-estradiol-e2-como-y-con-tratamiento-recibido-treat-como-x.-use-gráfico-de-puntos.-tip-use-geomtría-geom_point.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#cree-otro-gráfico-que-relacione-estradiol-e2-como-y-con-tratamiento-recibido-treat-como-x.-use-gráfico-de-puntos.-tip-use-geomtría-geom_point.",
    "title": "Mi primer ggplot",
    "section": "Cree otro gráfico que relacione estradiol (e2 como y) con tratamiento recibido (treat como x). Use gráfico de puntos. Tip: use geomtría geom_point().",
    "text": "Cree otro gráfico que relacione estradiol (e2 como y) con tratamiento recibido (treat como x). Use gráfico de puntos. Tip: use geomtría geom_point().\n\n\nCódigo\nggplot(datos, \n       aes(x = treat, y = e2)) + \n  geom_point()"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#guarde-este-gráfico-como-un-objeto-pongale-de-nombre-plot1.-tip-use-operador-asignar--.-imprima-plot1",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#guarde-este-gráfico-como-un-objeto-pongale-de-nombre-plot1.-tip-use-operador-asignar--.-imprima-plot1",
    "title": "Mi primer ggplot",
    "section": "Guarde este gráfico como un objeto, pongale de nombre: plot1. Tip: Use operador asignar <-. Imprima plot1",
    "text": "Guarde este gráfico como un objeto, pongale de nombre: plot1. Tip: Use operador asignar <-. Imprima plot1\n\n\nCódigo\nplot1 <- ggplot(datos, \n       aes(x = treat, y = e2)) + \n  geom_point()\n\n\n\n\nCódigo\nplot1"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#agregue-una-geometría-de-gráfico-de-cajas.-tip-agregue-geom_boxplot.",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#agregue-una-geometría-de-gráfico-de-cajas.-tip-agregue-geom_boxplot.",
    "title": "Mi primer ggplot",
    "section": "Agregue una geometría de gráfico de cajas. Tip: Agregue geom_boxplot().",
    "text": "Agregue una geometría de gráfico de cajas. Tip: Agregue geom_boxplot().\n\nOpción 1: Ampliar el código usando geometrías:\n\n\n\nCódigo\nggplot(datos, \n       aes(x = treat, y = e2)) + \n  geom_point() + \n  geom_boxplot()\n\n\n\n\n\n\nOpción 2: Reutilizar el objeto ggplot:\n\n\n\nCódigo\nplot1 + \n  geom_boxplot()"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#invierta-el-orden-de-las-geometrías.-primero-ponga-geom_boxplot-y-luego-ponga-geom_point.-compare-con-el-gráfico-anterior.-en-qué-se-diferencian",
    "href": "example/mi_primer_ggplot/mi_primer_ggplot_solucion.html#invierta-el-orden-de-las-geometrías.-primero-ponga-geom_boxplot-y-luego-ponga-geom_point.-compare-con-el-gráfico-anterior.-en-qué-se-diferencian",
    "title": "Mi primer ggplot",
    "section": "Invierta el orden de las geometrías. Primero ponga geom_boxplot() y luego ponga geom_point(). Compare con el gráfico anterior. ¿En qué se diferencian?",
    "text": "Invierta el orden de las geometrías. Primero ponga geom_boxplot() y luego ponga geom_point(). Compare con el gráfico anterior. ¿En qué se diferencian?\n\n\nCódigo\nggplot(datos, \n       aes(x = treat, y = e2)) + \n  geom_boxplot() + \n  geom_point()"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html",
    "title": "MI segundo grafico ggplot2",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(haven)\nlibrary(rio)\nlibrary(ggplot2)"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#importar-datos",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#importar-datos",
    "title": "MI segundo grafico ggplot2",
    "section": "Importar datos",
    "text": "Importar datos\n\n\nCódigo\ndatos <- as_factor(read_stata(\"maca_meno_fase1.dta\"))"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#inspeccionar-datos",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#inspeccionar-datos",
    "title": "MI segundo grafico ggplot2",
    "section": "Inspeccionar datos",
    "text": "Inspeccionar datos"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).",
    "text": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-otro-gráfico-que-también-diferencie-los-grupos-de-tratamiento-variable-treat-mediante-colores-diferentes.-tip-mapee-colour-con-treat.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-otro-gráfico-que-también-diferencie-los-grupos-de-tratamiento-variable-treat-mediante-colores-diferentes.-tip-mapee-colour-con-treat.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree otro gráfico que también diferencie los grupos de tratamiento (variable treat) mediante colores diferentes. Tip: mapee colour con treat.",
    "text": "Cree otro gráfico que también diferencie los grupos de tratamiento (variable treat) mediante colores diferentes. Tip: mapee colour con treat."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-otro-gráfico-que-taambién-diferencie-el-tiempo-de-medición-variable-time-con-formas-diferentes.-tip-mapee-shape-con-time.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#cree-otro-gráfico-que-taambién-diferencie-el-tiempo-de-medición-variable-time-con-formas-diferentes.-tip-mapee-shape-con-time.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree otro gráfico que taambién diferencie el tiempo de medición (variable time) con formas diferentes. Tip: mapee shape con time.",
    "text": "Cree otro gráfico que taambién diferencie el tiempo de medición (variable time) con formas diferentes. Tip: mapee shape con time."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#reutilizando-el-código-anterior-configure-la-transparencie-en-0.5.-tip-configure-el-alpha-dentro-de-la-geometría.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#reutilizando-el-código-anterior-configure-la-transparencie-en-0.5.-tip-configure-el-alpha-dentro-de-la-geometría.",
    "title": "MI segundo grafico ggplot2",
    "section": "Reutilizando el código anterior, configure la transparencie en 0.5. Tip: configure el alpha dentro de la geometría.",
    "text": "Reutilizando el código anterior, configure la transparencie en 0.5. Tip: configure el alpha dentro de la geometría."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#aplique-una-transformación-logarítmica-a-la-variable-fsh.-tipo-aplique-log-directamente-sobre-la-variable-fsh-dentro-del-chunk-de-código-ya-elaborado.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#aplique-una-transformación-logarítmica-a-la-variable-fsh.-tipo-aplique-log-directamente-sobre-la-variable-fsh-dentro-del-chunk-de-código-ya-elaborado.",
    "title": "MI segundo grafico ggplot2",
    "section": "Aplique una transformación logarítmica a la variable fsh. Tipo: Aplique log() directamente sobre la variable fsh dentro del chunk de código ya elaborado.",
    "text": "Aplique una transformación logarítmica a la variable fsh. Tipo: Aplique log() directamente sobre la variable fsh dentro del chunk de código ya elaborado."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#divida-en-facetas-los-gráficos-1-una-faceta-para-cada-tratamiento-y-2-una-faceta-para-tratamiento-tiempo.-tip-use-facet__wrap-y-facet_grid",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#divida-en-facetas-los-gráficos-1-una-faceta-para-cada-tratamiento-y-2-una-faceta-para-tratamiento-tiempo.-tip-use-facet__wrap-y-facet_grid",
    "title": "MI segundo grafico ggplot2",
    "section": "Divida en facetas los gráficos: 1) Una faceta para cada tratamiento; y 2) Una faceta para tratamiento – tiempo. Tip: Use facet__wrap() y facet_grid()",
    "text": "Divida en facetas los gráficos: 1) Una faceta para cada tratamiento; y 2) Una faceta para tratamiento – tiempo. Tip: Use facet__wrap() y facet_grid()\n\nUna faceta para cada tratamiento:\n\n\n\n\n\n\n\nUna faceta para tratamiento – tiempo"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#utilice-el-tema-completo-theme_bw.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#utilice-el-tema-completo-theme_bw.",
    "title": "MI segundo grafico ggplot2",
    "section": "Utilice el tema completo theme_bw().",
    "text": "Utilice el tema completo theme_bw()."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot.html#bonus-temas-extra",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot.html#bonus-temas-extra",
    "title": "MI segundo grafico ggplot2",
    "section": "Bonus: Temas extra",
    "text": "Bonus: Temas extra"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html",
    "title": "MI segundo grafico ggplot2",
    "section": "",
    "text": "Código\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(haven)\nlibrary(rio)\nlibrary(ggplot2)"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#importar-datos",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#importar-datos",
    "title": "MI segundo grafico ggplot2",
    "section": "Importar datos",
    "text": "Importar datos\n\n\nCódigo\ndatos <- as_factor(read_stata(\"maca_meno_fase1.dta\"))"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#inspeccionar-datos",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#inspeccionar-datos",
    "title": "MI segundo grafico ggplot2",
    "section": "Inspeccionar datos",
    "text": "Inspeccionar datos\n\n\nCódigo\nglimpse(datos)\n\n\nRows: 106\nColumns: 14\n$ id         <dbl> 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 1…\n$ time       <fct> Baseline, 3 months, Baseline, 3 months, Baseline, 3 months,…\n$ treat      <fct> Placebo, Placebo, Dosis 2, Dosis 2, Dosis 1, Dosis 1, Dosis…\n$ age        <dbl> 33, 32, 27, 27, 25, 25, 37, 38, 31, 32, 38, 38, 26, 26, 34,…\n$ race       <chr> \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mestiza\", \"Mes…\n$ married    <fct> Single, Single, Single, Single, Single, Single, Divorced, D…\n$ married2   <fct> Without couple, Without couple, Without couple, Without cou…\n$ procedence <chr> \"Callao\", \"Callao\", \"Santa Anita\", \"Santa Anita\", \"Callao\",…\n$ weight     <dbl> 59.0, 59.9, 62.0, 62.1, 62.0, 60.0, 60.9, 61.4, 64.0, 58.1,…\n$ height     <dbl> 1.4, 1.3, 1.5, 1.6, 1.6, 1.6, 1.5, 1.5, 1.5, 1.6, 1.5, 1.5,…\n$ e2         <dbl> 87.30, 210.05, 169.01, 99.91, 78.76, 155.04, 40.99, 109.03,…\n$ lh         <dbl> 3.28, 26.85, 6.34, 5.77, 11.86, 10.14, 4.57, 7.29, 7.81, 9.…\n$ fsh        <dbl> 1.95, 8.83, 4.32, 1.70, 2.81, 4.51, 3.81, 2.39, 2.01, 3.66,…\n$ prog       <dbl> 14.20, 12.95, 0.50, 9.61, 10.46, 5.04, 4.64, 11.73, 15.11, …"
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-un-gráfico-de-dispersión-de-puntos-que-relacione-el-peso-variable-weight-en-el-eje-x-con-la-hormona-foliculo-estimulante-variable-fsh-en-el-eje-y.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).",
    "text": "Cree un gráfico de dispersión de puntos que relacione el peso (variable weight, en el eje x) con la hormona foliculo estimulante (variable fsh, en el eje y).\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = fsh)) + \n  geom_point()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-otro-gráfico-que-también-diferencie-los-grupos-de-tratamiento-variable-treat-mediante-colores-diferentes.-tip-mapee-colour-con-treat.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-otro-gráfico-que-también-diferencie-los-grupos-de-tratamiento-variable-treat-mediante-colores-diferentes.-tip-mapee-colour-con-treat.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree otro gráfico que también diferencie los grupos de tratamiento (variable treat) mediante colores diferentes. Tip: mapee colour con treat.",
    "text": "Cree otro gráfico que también diferencie los grupos de tratamiento (variable treat) mediante colores diferentes. Tip: mapee colour con treat.\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = fsh, colour = treat)) + \n  geom_point()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-otro-gráfico-que-taambién-diferencie-el-tiempo-de-medición-variable-time-con-formas-diferentes.-tip-mapee-shape-con-time.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#cree-otro-gráfico-que-taambién-diferencie-el-tiempo-de-medición-variable-time-con-formas-diferentes.-tip-mapee-shape-con-time.",
    "title": "MI segundo grafico ggplot2",
    "section": "Cree otro gráfico que taambién diferencie el tiempo de medición (variable time) con formas diferentes. Tip: mapee shape con time.",
    "text": "Cree otro gráfico que taambién diferencie el tiempo de medición (variable time) con formas diferentes. Tip: mapee shape con time.\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = fsh, colour = treat, shape = time)) + \n  geom_point()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#reutilizando-el-código-anterior-configure-la-transparencie-en-0.5.-tip-configure-el-alpha-dentro-de-la-geometría.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#reutilizando-el-código-anterior-configure-la-transparencie-en-0.5.-tip-configure-el-alpha-dentro-de-la-geometría.",
    "title": "MI segundo grafico ggplot2",
    "section": "Reutilizando el código anterior, configure la transparencie en 0.5. Tip: configure el alpha dentro de la geometría.",
    "text": "Reutilizando el código anterior, configure la transparencie en 0.5. Tip: configure el alpha dentro de la geometría.\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = fsh, colour = treat, shape = time)) + \n  geom_point(alpha = 0.5)\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#aplique-una-transformación-logarítmica-a-la-variable-fsh.-tipo-aplique-log-directamente-sobre-la-variable-fsh-dentro-del-chunk-de-código-ya-elaborado.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#aplique-una-transformación-logarítmica-a-la-variable-fsh.-tipo-aplique-log-directamente-sobre-la-variable-fsh-dentro-del-chunk-de-código-ya-elaborado.",
    "title": "MI segundo grafico ggplot2",
    "section": "Aplique una transformación logarítmica a la variable fsh. Tipo: Aplique log() directamente sobre la variable fsh dentro del chunk de código ya elaborado.",
    "text": "Aplique una transformación logarítmica a la variable fsh. Tipo: Aplique log() directamente sobre la variable fsh dentro del chunk de código ya elaborado.\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5)\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#divida-en-facetas-los-gráficos-1-una-faceta-para-cada-tratamiento-y-2-una-faceta-para-tratamiento-tiempo.-tip-use-facet__wrap-y-facet_grid",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#divida-en-facetas-los-gráficos-1-una-faceta-para-cada-tratamiento-y-2-una-faceta-para-tratamiento-tiempo.-tip-use-facet__wrap-y-facet_grid",
    "title": "MI segundo grafico ggplot2",
    "section": "Divida en facetas los gráficos: 1) Una faceta para cada tratamiento; y 2) Una faceta para tratamiento – tiempo. Tip: Use facet__wrap() y facet_grid()",
    "text": "Divida en facetas los gráficos: 1) Una faceta para cada tratamiento; y 2) Una faceta para tratamiento – tiempo. Tip: Use facet__wrap() y facet_grid()\n\nUna faceta para cada tratamiento:\n\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_grid(.~treat)\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_grid(treat~.)\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\nUna faceta para tratamiento – tiempo\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_wrap(treat ~ time)\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_wrap(time ~ treat)\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#utilice-el-tema-completo-theme_bw.",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#utilice-el-tema-completo-theme_bw.",
    "title": "MI segundo grafico ggplot2",
    "section": "Utilice el tema completo theme_bw().",
    "text": "Utilice el tema completo theme_bw().\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_wrap(time ~ treat) + \n  theme_bw()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#bonus-temas-extra",
    "href": "example/mi_primer_ggplot/mi_segundo_ggplot_solucion.html#bonus-temas-extra",
    "title": "MI segundo grafico ggplot2",
    "section": "Bonus: Temas extra",
    "text": "Bonus: Temas extra\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_wrap(time ~ treat) + \n  theme_minimal()\n\n\nWarning: Removed 3 rows containing missing values (geom_point).\n\n\n\n\n\n\n\nCódigo\nggplot(datos, \n       aes(x = weight, y = log(fsh), colour = treat, shape = time)) + \n  geom_point(alpha = 0.5) + \n  facet_wrap(time ~ treat) + \n  theme_classic()\n\n\nWarning: Removed 3 rows containing missing values (geom_point)."
  },
  {
    "objectID": "example/mi_primer_manejo_datos/mi_primer_manejo_datos.html",
    "href": "example/mi_primer_manejo_datos/mi_primer_manejo_datos.html",
    "title": "Mi primer manejo de datos - Taller",
    "section": "",
    "text": "Descripción: En este taller nos familizaremos con el manejo de datos\nRealice las siguientes acciones en su computador:\n\nTrabaje sobre este documento Quarto.\nImportaremos el conjunto de datos maca_meno_fase1.dta y lo guardaremos con el nombre de datos."
  },
  {
    "objectID": "example/mi_primer_manejo_datos/mi_primer_manejo_datos.html#desarrollo-del-taller",
    "href": "example/mi_primer_manejo_datos/mi_primer_manejo_datos.html#desarrollo-del-taller",
    "title": "Mi primer manejo de datos - Taller",
    "section": "Desarrollo del taller",
    "text": "Desarrollo del taller\n\nCargar los paquetes\nCon este código se cargan los paquetes. Es recomendable instalar todos los paquetes al inicio y luego cargarlos todos! Solo instala una vez, luego comenta para no reinstalar a cada rato.\nTip: Use library(paquete). Cargue tidyverse, haven y labelled. Si no están instalados, instalelos.\n\n\n\n\n\nImportar datos\nTip: Como es archivo Stata, use read_stata() junto con as_factor() para recuperar metadatos.\n\n\n\n\n\nFiltre al grupo tratado placebo y guardelo como datos2. Imprima datos2\nTip: Use filter()\n\n\n\n\n\nFiltre a quienes tienen edad > 27 y menor de 33 sin guardarlo, solo imprimalo:\nTip: Use filter()\n\n\n\n\n\nSelecciona las variables id, treat, age y married. Guarde como data3 e imprima.\n\n\n\n\n\nElimine las variables married2 y weight. No guarde solo imprima.\n\n\n\n\n\nSeleccione id, time y race y married2. Luego, filtre por status marital sin pareja.\n\n\n\n\n\nSeleccione id, treat, weight y height. Luego, calcule el indice de masa corporal. Guarde como data4 e imprima. Llame a esta variable imc.\nTip: Anide select() con mutate()\n\n\n\n\n\nCategorice edad en edad 20-25, 26-35, 36-41. Guarde como data5 e imprima.\n\n\n\n\n\nCree una variable nueva llamada elegibilidad, que tenga dos valores: elegible cuando el estado marital es con pareja, no proceda de Callao y tenga IMC mayor a 20, caso contrario, denominarlo no elegible.\n\n\n\n\n\nCategorice indice de masa corporal en <18.5 (Bajo peso), 18.5 a 24.9 (peso normal), 25-29.9 (sobrepeso) y 30+ (obeso). Llame a esta variable imc_cat. GUarde como data6 e imprima\n\n\n\n\n\nColoque etiquetas a imc y a imc_cat para que otro investigador entienda su significado.\n\n\n\n\n\nCambiar el nombre del imc a bmi y de imc_cat bmicat\n\n\n\n\n\nQuedarse solo con las filas 1, 3, 5 y 8 de los datos:\n\n\n\n\n\nSeleccionar, id, peso, tratamiento y imc y reordenarlo segun imc de mayor a menor:"
  },
  {
    "objectID": "example/mi_primer_manejo_datos/mi_primer_manejo_datos_solucion.html",
    "href": "example/mi_primer_manejo_datos/mi_primer_manejo_datos_solucion.html",
    "title": "Mi primer manejo de datos",
    "section": "",
    "text": "Descripción: En este taller nos familizaremos con el manejo de datos\nRealice las siguientes acciones en su computador:\n\nTrabaje sobre este documento Quarto.\nImportaremos el conjunto de datos maca_meno_fase1.dta y lo guardaremos con el nombre de datos."
  },
  {
    "objectID": "example/mi_primer_manejo_datos/mi_primer_manejo_datos_solucion.html#desarrollo-del-taller",
    "href": "example/mi_primer_manejo_datos/mi_primer_manejo_datos_solucion.html#desarrollo-del-taller",
    "title": "Mi primer manejo de datos",
    "section": "Desarrollo del taller",
    "text": "Desarrollo del taller\n\nCargar los paquetes\nCon este código se cargan los paquetes. Es recomendable instalar todos los paquetes al inicio y luego cargarlos todos! Solo instala una vez, luego comenta para no reinstalar a cada rato.\nTip: Use library(paquete). Cargue tidyverse, haven y labelled. Si no están instalados, instalelos.\n\n\nCódigo\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n\n\nCódigo\nlibrary(labelled)\nlibrary(haven)\n\n\n\n\nImportar datos\nTip: Como es archivo Stata, use read_stata() junto con as_factor() para recuperar metadatos.\n\n\nCódigo\ndatos <- read_stata(\"maca_meno_fase1.dta\") %>% \n  as_factor()\n\ndatos\n\n\n# A tibble: 106 × 14\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 3 more variables: lh <dbl>, fsh <dbl>, prog <dbl>, and\n#   abbreviated variable names ¹​married2, ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nFiltre al grupo tratado placebo y guardelo como datos2. Imprima datos2\nTip: Use filter()\n\n\nCódigo\ndatos %>% \n  filter(treat == \"Placebo\") -> datos2\n\ndatos2\n\n\n# A tibble: 34 × 14\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n 4     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n 5     6 Baseline Place…    38 Mest… Married With c… Los Ol…   54.5    1.5  36.2\n 6     6 3 months Place…    38 Mest… Married With c… Los Ol…   53.9    1.5  44.7\n 7     8 Baseline Place…    34 Mest… Married With c… Caraba…   64      1.5  65.6\n 8     8 3 months Place…    34 Mest… Married With c… Caraba…   59      1.5 134. \n 9    10 Baseline Place…    38 Mest… Single  Withou… Pueblo…   56.1    1.7 115. \n10    10 3 months Place…    38 Mest… Single  Withou… Pueblo…   54.9    1.5  71.5\n# … with 24 more rows, 3 more variables: lh <dbl>, fsh <dbl>, prog <dbl>, and\n#   abbreviated variable names ¹​married2, ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nFiltre a quienes tienen edad > 27 y menor de 33 sin guardarlo, solo imprimalo:\nTip: Use filter()\n\n\nCódigo\ndatos %>% \n  filter(age > 27 & age < 33) \n\n\n# A tibble: 25 × 14\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 2     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n 3     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n 4     9 Baseline Dosis…    30 Mest… Single  Withou… SMP       61      1.6  49.6\n 5     9 3 months Dosis…    30 Mest… Single  Withou… SMP       63.1    1.7  46.3\n 6    16 Baseline Dosis…    30 Mest… Single  Withou… Los Ol…   56      1.5  81.0\n 7    16 3 months Dosis…    30 Mest… Single  Withou… Los Ol…   55.9    1.5  73.1\n 8    21 Baseline Place…    29 Mest… Married With c… SJL       56.9    1.4  71.6\n 9    21 3 months Place…    29 Mest… Married With c… SJL       57.1    1.5  29.6\n10    26 Baseline Place…    32 Mest… Married With c… Chosica   72.1    1.7 117. \n# … with 15 more rows, 3 more variables: lh <dbl>, fsh <dbl>, prog <dbl>, and\n#   abbreviated variable names ¹​married2, ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nSelecciona las variables id, treat, age y married. Guarde como data3 e imprima.\n\n\nCódigo\ndatos %>% \n  select(id, treat, age, married) -> data3\n\ndata3\n\n\n# A tibble: 106 × 4\n      id treat     age married \n   <dbl> <fct>   <dbl> <fct>   \n 1     1 Placebo    33 Single  \n 2     1 Placebo    32 Single  \n 3     2 Dosis 2    27 Single  \n 4     2 Dosis 2    27 Single  \n 5     3 Dosis 1    25 Single  \n 6     3 Dosis 1    25 Single  \n 7     4 Dosis 1    37 Divorced\n 8     4 Dosis 1    38 Divorced\n 9     5 Placebo    31 Single  \n10     5 Placebo    32 Single  \n# … with 96 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nElimine las variables married2 y weight. No guarde solo imprima.\n\n\nCódigo\ndatos %>% \n  select(-married2, -weight)\n\n\n# A tibble: 106 × 12\n      id time   treat   age race  married proce…¹ height    e2    lh   fsh  prog\n   <dbl> <fct>  <fct> <dbl> <chr> <fct>   <chr>    <dbl> <dbl> <dbl> <dbl> <dbl>\n 1     1 Basel… Plac…    33 Mest… Single  Callao     1.4  87.3  3.28  1.95 14.2 \n 2     1 3 mon… Plac…    32 Mest… Single  Callao     1.3 210.  26.8   8.83 13.0 \n 3     2 Basel… Dosi…    27 Mest… Single  Santa …    1.5 169.   6.34  4.32  0.5 \n 4     2 3 mon… Dosi…    27 Mest… Single  Santa …    1.6  99.9  5.77  1.7   9.61\n 5     3 Basel… Dosi…    25 Mest… Single  Callao     1.6  78.8 11.9   2.81 10.5 \n 6     3 3 mon… Dosi…    25 Mest… Single  Callao     1.6 155.  10.1   4.51  5.04\n 7     4 Basel… Dosi…    37 Mest… Divorc… Callao     1.5  41.0  4.57  3.81  4.64\n 8     4 3 mon… Dosi…    38 Mest… Divorc… Callao     1.5 109.   7.29  2.39 11.7 \n 9     5 Basel… Plac…    31 Mest… Single  La Mol…    1.5  43.0  7.81  2.01 15.1 \n10     5 3 mon… Plac…    32 Mest… Single  La Mol…    1.6  56.0  9.15  3.66 11.5 \n# … with 96 more rows, and abbreviated variable name ¹​procedence\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nSeleccione id, time y race y married2. Luego, filtre por status marital sin pareja.\n\n\nCódigo\ndatos %>% \n  select(id, time, race, married2) %>% \n  filter(married2 == \"Without couple\")\n\n\n# A tibble: 54 × 4\n      id time     race    married2      \n   <dbl> <fct>    <chr>   <fct>         \n 1     1 Baseline Mestiza Without couple\n 2     1 3 months Mestiza Without couple\n 3     2 Baseline Mestiza Without couple\n 4     2 3 months Mestiza Without couple\n 5     3 Baseline Mestiza Without couple\n 6     3 3 months Mestiza Without couple\n 7     4 Baseline Mestiza Without couple\n 8     4 3 months Mestiza Without couple\n 9     5 Baseline Mestiza Without couple\n10     5 3 months Mestiza Without couple\n# … with 44 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nSeleccione id, treat, weight y height. Luego, calcule el indice de masa corporal. Guarde como data4 e imprima. Llame a esta variable imc.\nTip: Anide select() con mutate()\n\n\nCódigo\ndata4 <- datos %>% \n  select(id, treat, weight, height) %>% \n  mutate(imc = weight / height ^ 2) # ^ : ALT + 94\n\ndata4\n\n\n# A tibble: 106 × 5\n      id treat   weight height   imc\n   <dbl> <fct>    <dbl>  <dbl> <dbl>\n 1     1 Placebo   59      1.4  30.1\n 2     1 Placebo   59.9    1.3  35.4\n 3     2 Dosis 2   62      1.5  27.6\n 4     2 Dosis 2   62.1    1.6  24.3\n 5     3 Dosis 1   62      1.6  24.2\n 6     3 Dosis 1   60      1.6  23.4\n 7     4 Dosis 1   60.9    1.5  27.1\n 8     4 Dosis 1   61.4    1.5  27.3\n 9     5 Placebo   64      1.5  28.4\n10     5 Placebo   58.1    1.6  22.7\n# … with 96 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\n\n\n\nCategorice edad en edad 20-25, 26-35, 36-41. Guarde como data5 e imprima.\n\n\nCódigo\ndatos %>% \n  mutate(\n    edad_cat = case_when(\n      age >= 20 & age <= 25 ~ \"20-25 años\", \n      age >= 26 & age <= 35 ~ \"26-35 años\", \n      age >= 36 & age <= 41 ~ \"36-41 años\", \n      TRUE ~ as.character(NA)\n    )\n  ) -> data5\n\n\ndata5\n\n\n# A tibble: 106 × 15\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 4 more variables: lh <dbl>, fsh <dbl>, prog <dbl>,\n#   edad_cat <chr>, and abbreviated variable names ¹​married2, ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nCree una variable nueva llamada elegibilidad, que tenga dos valores: elegible cuando el estado marital es con pareja, no proceda de Callao y tenga IMC mayor a 20, caso contrario, denominarlo no elegible.\n\n\nCódigo\ndatos %>% \n  mutate(\n    imc = weight / height ^ 2, \n    elegibilidad = case_when(\n      married2 == \"With couple\" & procedence != \"Callao\" & imc > 20 ~ \"Elegible\", \n      TRUE ~ \"No elegible\"\n    )\n  )\n\n\n# A tibble: 106 × 16\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 5 more variables: lh <dbl>, fsh <dbl>, prog <dbl>,\n#   imc <dbl>, elegibilidad <chr>, and abbreviated variable names ¹​married2,\n#   ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nCategorice indice de masa corporal en <18.5 (Bajo peso), 18.5 a 24.9 (peso normal), 25-29.9 (sobrepeso) y 30+ (obeso). Llame a esta variable imc_cat. GUarde como data6 e imprima\n\n\nCódigo\ndatos %>% \n  mutate(\n    imc = weight / height ^ 2, \n    imc_cat = case_when(\n      imc < 18.5 ~ \"<18.5 (Bajo peso)\", \n      imc >= 18.5 & imc < 25 ~ \"18.5 a 24.9 (peso normal)\", \n      imc >= 25 & imc < 30 ~ \"25-29.9 (sobrepeso)\", \n      imc >= 30 ~ \"30+ (obeso)\"\n    )\n  ) -> data6\n\ndata6\n\n\n# A tibble: 106 × 16\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 5 more variables: lh <dbl>, fsh <dbl>, prog <dbl>,\n#   imc <dbl>, imc_cat <chr>, and abbreviated variable names ¹​married2,\n#   ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nColoque etiquetas a imc y a imc_cat para que otro investigador entienda su significado.\n\n\nCódigo\ndata6 %>% \n  set_variable_labels(\n    imc = \"Índice de Masa Corporal (kg/m2)\", \n    imc_cat = \"Categoría de IMC según OMS\"\n  ) -> data7\n\ndata7\n\n\n# A tibble: 106 × 16\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 5 more variables: lh <dbl>, fsh <dbl>, prog <dbl>,\n#   imc <dbl>, imc_cat <chr>, and abbreviated variable names ¹​married2,\n#   ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nCambiar el nombre del imc a bmi y de imc_cat bmicat\n\n\nCódigo\ndata7 %>% \n  rename(\n    bmi = imc,\n    bmicat = imc_cat\n  ) -> data8\n\ndata8\n\n\n# A tibble: 106 × 16\n      id time     treat    age race  married marri…¹ proce…² weight height    e2\n   <dbl> <fct>    <fct>  <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n 1     1 Baseline Place…    33 Mest… Single  Withou… Callao    59      1.4  87.3\n 2     1 3 months Place…    32 Mest… Single  Withou… Callao    59.9    1.3 210. \n 3     2 Baseline Dosis…    27 Mest… Single  Withou… Santa …   62      1.5 169. \n 4     2 3 months Dosis…    27 Mest… Single  Withou… Santa …   62.1    1.6  99.9\n 5     3 Baseline Dosis…    25 Mest… Single  Withou… Callao    62      1.6  78.8\n 6     3 3 months Dosis…    25 Mest… Single  Withou… Callao    60      1.6 155. \n 7     4 Baseline Dosis…    37 Mest… Divorc… Withou… Callao    60.9    1.5  41.0\n 8     4 3 months Dosis…    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n 9     5 Baseline Place…    31 Mest… Single  Withou… La Mol…   64      1.5  43.0\n10     5 3 months Place…    32 Mest… Single  Withou… La Mol…   58.1    1.6  56.0\n# … with 96 more rows, 5 more variables: lh <dbl>, fsh <dbl>, prog <dbl>,\n#   bmi <dbl>, bmicat <chr>, and abbreviated variable names ¹​married2,\n#   ²​procedence\n# ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names\n\n\n\n\nQuedarse solo con las filas 1, 3, 5 y 8 de los datos:\n\n\nCódigo\ndata8 %>% \n  slice(c(1, 3, 5, 8))\n\n\n# A tibble: 4 × 16\n     id time     treat     age race  married marri…¹ proce…² weight height    e2\n  <dbl> <fct>    <fct>   <dbl> <chr> <fct>   <fct>   <chr>    <dbl>  <dbl> <dbl>\n1     1 Baseline Placebo    33 Mest… Single  Withou… Callao    59      1.4  87.3\n2     2 Baseline Dosis 2    27 Mest… Single  Withou… Santa …   62      1.5 169. \n3     3 Baseline Dosis 1    25 Mest… Single  Withou… Callao    62      1.6  78.8\n4     4 3 months Dosis 1    38 Mest… Divorc… Withou… Callao    61.4    1.5 109. \n# … with 5 more variables: lh <dbl>, fsh <dbl>, prog <dbl>, bmi <dbl>,\n#   bmicat <chr>, and abbreviated variable names ¹​married2, ²​procedence\n# ℹ Use `colnames()` to see all variable names\n\n\n\n\nSeleccionar, id, peso, tratamiento y imc y reordenarlo segun imc de mayor a menor:\n\n\nCódigo\ndata8 %>% \n  select(id, weight, treat, bmi) %>% \n  arrange(desc(bmi))\n\n\n# A tibble: 106 × 4\n      id weight treat     bmi\n   <dbl>  <dbl> <fct>   <dbl>\n 1    41   91.9 Dosis 1  40.8\n 2    50   71.7 Dosis 2  36.6\n 3    36   81   Dosis 1  36  \n 4     1   59.9 Placebo  35.4\n 5    53   64.9 Dosis 2  33.1\n 6    34   72.6 Dosis 1  32.3\n 7    41   92.1 Dosis 1  31.9\n 8    28   81.5 Dosis 2  31.8\n 9    12   68   Dosis 2  30.2\n10    12   68   Dosis 2  30.2\n# … with 96 more rows\n# ℹ Use `print(n = ...)` to see more rows"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html",
    "title": "Mi primer documento quarto",
    "section": "",
    "text": "Todo lo que se escriba en el documento quarto será entendido como texto en lenguaje humano por quarto.\nPor ejemplo, las siguientes operaciones matemáticas:\n5 + 8\n3 * 23\n20 ^ 3\n73 / 5\nTodas ellas se han impreso, pero no se ha mostrado resultado. Esto debido a que Quarto las entiende como texto."
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#hacer-cálculos-con-r",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#hacer-cálculos-con-r",
    "title": "Mi primer documento quarto",
    "section": "Hacer cálculos con R",
    "text": "Hacer cálculos con R\nSi queremos hacer cálculos con R en Quarto, debemos hacerlo dentro de chunks de código. Vean los siguientes ejemplos:\n\ncinco más ocho\n\n\n\nCódigo\n5 + 8\n\n\n[1] 13\n\n\n\ntres por veintitrés\n\n\n\nCódigo\n3 * 23\n\n\n[1] 69\n\n\n\nveinte elevado al cubo\n\n\n\nCódigo\n20 ^ 3\n\n\n[1] 8000\n\n\n\nsetenta y tres entre cinco\n\n\n\nCódigo\n73 / 5\n\n\n[1] 14.6"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#instalación-de-paquetes",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#instalación-de-paquetes",
    "title": "Mi primer documento quarto",
    "section": "Instalación de paquetes:",
    "text": "Instalación de paquetes:\nUna de las primeras cosas que uno debe hacer es instalar paquetes. Una forma de hacerlo es a través de install.packages(). Los paquetes debería instalarse solo la primera vez, por lo que sugerimos no colocarlos en los chunk de código y solamente correrlos desde la consola.\nEn nuestro caso, los hemos puesto dentro del chunk del código, pero para evitar que se vuelvan a correr, los hemos comentado con el síbolo # al inicio de cada línea.\nEl símbolo # dentro de un chunk de código ocasiona que este no sea procesado por R. Se transforma en un “comentario humano”. Si no colocamos el signo #, entonces R procesará el texto como código y ejecutará la acción correspondiente.\n\n\nCódigo\n# install.packages(\"medicaldata\")\n# install.packages(\"tidyverse\")\n\n### Nota: Uno solo instala los paquetes la primera vez, luego es RECOMENDABLE comentarlos con el símbolo inicial #. Si no se hace esto, suelen aparecer mensajes de error.\n\n\nNota: Uno solo instala los paquetes la primera vez, luego es RECOMENDABLE comentarlos con el símbolo inicial #. Si no se hace esto, suelen aparecer mensajes de error."
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#cargar-paquetes",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#cargar-paquetes",
    "title": "Mi primer documento quarto",
    "section": "Cargar paquetes",
    "text": "Cargar paquetes\nUna de las primeras acciones que uno debe realizar es cargar los paquetes que usará. Por un tema de orden, sugerimos que estos siempre se carguen en un solo chunk que se encuentre al inicio del documento Quarto.\n\n\nCódigo\nlibrary(medicaldata)\nlibrary(tidyverse)\n\n\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n\n\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.8     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#consultar-ayuda-de-filter",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#consultar-ayuda-de-filter",
    "title": "Mi primer documento quarto",
    "section": "Consultar ayuda de filter()",
    "text": "Consultar ayuda de filter()\nLa función ? permite consultar la ayuda en R.\n\n\nCódigo\n?filter\n\n\nstarting httpd help server ... done"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#cargar-base-de-datos-theoph-de-medicaldata",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#cargar-base-de-datos-theoph-de-medicaldata",
    "title": "Mi primer documento quarto",
    "section": "Cargar base de datos theoph de medicaldata",
    "text": "Cargar base de datos theoph de medicaldata\nSe puede cargar los datos de un paquete usando la función data().\n\n\nCódigo\ndata(theoph)"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#seleccionar-columna-dose-de-datos-theoph",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#seleccionar-columna-dose-de-datos-theoph",
    "title": "Mi primer documento quarto",
    "section": "Seleccionar columna Dose de datos theoph",
    "text": "Seleccionar columna Dose de datos theoph\nPodemos seleccionar una columna del objeto data frame theoph usndo el operador $.\n\n\nCódigo\ntheoph$Dose\n\n\n  [1] 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.02 4.40 4.40 4.40 4.40\n [16] 4.40 4.40 4.40 4.40 4.40 4.40 4.40 4.53 4.53 4.53 4.53 4.53 4.53 4.53 4.53\n [31] 4.53 4.53 4.53 4.40 4.40 4.40 4.40 4.40 4.40 4.40 4.40 4.40 4.40 4.40 5.86\n [46] 5.86 5.86 5.86 5.86 5.86 5.86 5.86 5.86 5.86 5.86 4.00 4.00 4.00 4.00 4.00\n [61] 4.00 4.00 4.00 4.00 4.00 4.00 4.95 4.95 4.95 4.95 4.95 4.95 4.95 4.95 4.95\n [76] 4.95 4.95 4.53 4.53 4.53 4.53 4.53 4.53 4.53 4.53 4.53 4.53 4.53 3.10 3.10\n [91] 3.10 3.10 3.10 3.10 3.10 3.10 3.10 3.10 3.10 5.50 5.50 5.50 5.50 5.50 5.50\n[106] 5.50 5.50 5.50 5.50 5.50 4.92 4.92 4.92 4.92 4.92 4.92 4.92 4.92 4.92 4.92\n[121] 4.92 5.30 5.30 5.30 5.30 5.30 5.30 5.30 5.30 5.30 5.30 5.30"
  },
  {
    "objectID": "example/mi_primer_proyecto/mi_primer_quarto.html#guardar-columna-seleccionada-en-dosis",
    "href": "example/mi_primer_proyecto/mi_primer_quarto.html#guardar-columna-seleccionada-en-dosis",
    "title": "Mi primer documento quarto",
    "section": "Guardar columna seleccionada en dosis",
    "text": "Guardar columna seleccionada en dosis\nUno puede guardar el objeto extraido con el operador $ en otro nuevo objeto cuyo nombre se asigna con el operador asignar <-\n\n\nCódigo\ndosis <- theoph$Dose"
  },
  {
    "objectID": "example/random-numbers.html",
    "href": "example/random-numbers.html",
    "title": "Generating random numbers",
    "section": "",
    "text": "In your final project, you will generate a synthetic dataset and use it to conduct an evaluation of some social program. Generating fake or simulated data is an incredibly powerful skill, but it takes some practice. Here are a bunch of helpful resources and code examples of how to use different R functions to generate random numbers that follow specific distributions (or probability shapes).\nThis example focuses primarily on distributions. Each of the columns you’ll generate will be completely independent from each other and there will be no correlation between them. The example for generating synthetic data provides code and a bunch of examples of how to build in correlations between columns.\nFirst, make sure you load the libraries we’ll use throughout the example:"
  },
  {
    "objectID": "example/random-numbers.html#seeds",
    "href": "example/random-numbers.html#seeds",
    "title": "Generating random numbers",
    "section": "Seeds",
    "text": "Seeds\nWhen R (or any computer program, really) generates random numbers, it uses an algorithm to simulate randomness. This algorithm always starts with an initial number, or seed. Typically it will use something like the current number of milliseconds since some date, so that every time you generate random numbers they’ll be different. Look at this, for instance:\n\n\nCódigo\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 9 4 7\n\n\n\n\nCódigo\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 5 6 9\n\n\nThey’re different both times.\nThat’s ordinarily totally fine, but if you care about reproducibility (like having a synthetic dataset with the same random values, or having jittered points in a plot be in the same position every time you knit), it’s a good idea to set your own seed. This ensures that the random numbers you generate are the same every time you generate them.\nDo this by feeding set.seed() some numbers. It doesn’t matter what number you use—it just has to be a whole number. People have all sorts of favorite seeds:\n\n1\n13\n42\n1234\n12345\n20201101 (i.e. the current date)\n8675309\n\nYou could even go to random.org and use atmospheric noise to generate a seed, and then use that in R.\nHere’s what happens when you generate random numbers after setting a seed:\n\n\nCódigo\n# Set a seed\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 10  6  5\n\n# Set a seed\nset.seed(1234)\n\n# Choose another 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 10  6  5\n\n\nThey’re the same!\nOnce you set a seed, it influences any function that does anything random, but it doesn’t reset. For instance, if you set a seed once and then run sample() twice, you’ll get different numbers the second time, but you’ll get the same different numbers every time:\n\n\nCódigo\n# Set a seed\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 10  6  5\nsample(1:10, 3)  # This will be different!\n## [1] 9 5 6\n\n# Set a seed again\nset.seed(1234)\n\n# Choose 3 numbers between 1 and 10\nsample(1:10, 3)\n## [1] 10  6  5\nsample(1:10, 3)  # This will be different, but the same as before!\n## [1] 9 5 6\n\n\nTypically it’s easiest to just include set.seed(SOME_NUMBER) at the top of your script after you load all the libraries. Some functions have a seed argument, and it’s a good idea to use it: position_jitter(..., seed = 1234)."
  },
  {
    "objectID": "example/random-numbers.html#distributions",
    "href": "example/random-numbers.html#distributions",
    "title": "Generating random numbers",
    "section": "Distributions",
    "text": "Distributions\nRemember in elementary school when you’d decide on playground turns by saying “Pick a number between 1 and 10” and whoever was the closest would win? When you generate random numbers in R, you’re essentially doing the same thing, only with some fancier bells and whistles.\nWhen you ask someone to choose a number between 1 and 10, any of those numbers should be equally likely. 1 isn’t really less common than 5 or anything. In some situations, though, there are numbers that are more likely to appear than others (i.e. when you roll two dice, it’s pretty rare to get a 2, but pretty common to get a 7). These different kinds of likelihood change the shape of the distribution of possible values. There are hundreds of different distributions, but for the sake of generating data, there are only a few that you need to know.\n\nUniform distribution\nIn a uniform distribution, every number is equally likely. This is the “pick a number between 1 and 10” scenario, or rolling a single die. There are a couple ways to work with a uniform distribution in R: (1) sample() and (2) runif().\n\nsample()\nThe sample() function chooses an element from a list.\nFor instance, let’s pretend we have six possible numbers (like a die, or like 6 categories on a survey), like this:\n\n\nCódigo\npossible_answers <- c(1, 2, 3, 4, 5, 6)  # We could also write this as 1:6 instead\n\n\nIf we want to randomly choose from this list, you’d use sample(). The size argument defines how many numbers to choose.\n\n\nCódigo\n# Choose 1 random number\nsample(possible_answers, size = 1)\n## [1] 4\n\n# Choose 3 random numbers\nsample(possible_answers, size = 3)\n## [1] 2 6 5\n\n\nOne important argument you can use is replace, which essentially puts the number back into the pool of possible numbers. Imagine having a bowl full of ping pong balls with the numbers 1–6 on them. If you take the number “3” out, you can’t draw it again. If you put it back in, you can pull it out again. The replace argument puts the number back after it’s drawn:\n\n\nCódigo\n# Choose 10 random numbers, with replacement\nsample(possible_answers, size = 10, replace = TRUE)\n##  [1] 6 4 6 6 6 4 4 5 4 3\n\n\nIf you don’t specify replace = TRUE, and you try to choose more numbers than are in the set, you’ll get an error:\n\n\nCódigo\n# Choose 8 numbers between 1 and 6, but don't replace them.\n# This won't work!\nsample(possible_answers, size = 8)\n## Error in sample.int(length(x), size, replace, prob): cannot take a sample larger than the population when 'replace = FALSE'\n\n\nIt’s hard to see patterns in the outcomes when generating just a handful of numbers, but easier when you do a lot. Let’s roll a die 1,000 times:\n\n\nCódigo\nset.seed(1234)\ndie <- tibble(value = sample(possible_answers,\n                             size = 1000,\n                             replace = TRUE))\ndie %>%\n  count(value)\n## # A tibble: 6 × 2\n##   value     n\n##   <dbl> <int>\n## 1     1   161\n## 2     2   153\n## 3     3   188\n## 4     4   149\n## 5     5   157\n## 6     6   192\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"1,000 rolls of a single die\")\n\n\n\n\n\n\n\n\n\nIn this case, 3 and 6 came up more often than the others, but that’s just because of randomness. If we rolled the die 100,000 times, the bars should basically be the same:\n\n\nCódigo\nset.seed(1234)\ndie <- tibble(value = sample(possible_answers,\n                             size = 100000,\n                             replace = TRUE))\n\nggplot(die, aes(x = value)) +\n  geom_bar() +\n  labs(title = \"100,000 rolls of a single die\")\n\n\n\n\n\n\n\n\n\n\n\nrunif()\nAnother way to generate uniformly distributed numbers is to use the runif() function (which is short for “random uniform”, and which took me years to realize, and for years I wondered why people used a function named “run if” when there’s no if statement anywhere??)\nrunif() will choose numbers between a minimum and a maximum. These numbers will not be whole numbers. By default, the min and max are 0 and 1:\n\n\nCódigo\nrunif(5)\n## [1] 0.09862 0.96294 0.88655 0.05623 0.44452\n\n\nHere are 5 numbers between 35 and 56:\n\n\nCódigo\nrunif(5, min = 35, max = 56)\n## [1] 46.83 42.89 37.75 53.22 46.13\n\n\nSince these aren’t whole numbers, you can round them to make them look more realistic (like, if you were generating a column for age, you probably don’t want people who are 21.5800283 years old):\n\n\nCódigo\n# Generate 5 people between the ages of 18 and 35\nround(runif(5, min = 18, max = 35), 0)\n## [1] 21 28 33 34 31\n\n\nYou can confirm that each number has equal probability if you make a histogram. Here are 5,000 random people between 18 and 35:\n\n\nCódigo\nset.seed(1234)\nlots_of_numbers <- tibble(x = runif(5000, min = 18, max = 35))\n\nggplot(lots_of_numbers, aes(x = x)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 18)\n\n\n\n\n\n\n\n\n\n\n\n\nNormal distribution\nThe whole “choose a number between 1 and 10” idea of a uniform distribution is neat and conceptually makes sense, but most numbers that exist in the world tend to have higher probabilities around certain values—almost like gravity around a specific point. For instance, income in the United States is not uniformly distributed—a handful of people are really really rich, lots are very poor, and most are kind of clustered around an average.\nThe idea of having possible values clustered around an average is how the rest of these distributions work (uniform distributions don’t have any sort of central gravity point; all these others do). Each distribution is defined by different things called parameters, or values that determine the shape of the probabilities and locations of the clusters.\nA super common type of distribution is the normal distribution. This is the famous “bell curve” you learn about in earlier statistics classes. A normal distribution has two parameters:\n\nA mean (the center of the cluster)\nA standard deviation (how much spread there is around the mean).\n\nIn R, you can generate random numbers from a normal distribution with the rnorm() function. It takes three arguments: the number of numbers you want to generate, the mean, and the standard deviation. It defaults to a mean of 0 and a standard deviation of 1, which means most numbers will cluster around 0, with a lot between −1 and 1, and some going up to −2 and 2 (technically 67% of numbers will be between −1 and 1, while 95% of numbers will be between −2–2ish)\n\n\nCódigo\nrnorm(5)\n## [1] -1.3662  0.5392 -1.3219 -0.2813 -2.1049\n\n# Cluster around 10, with an SD of 4\nrnorm(5, mean = 10, sd = 4)\n## [1]  3.530  7.105 11.227 10.902 13.743\n\n\nWhen working with uniform distributions, it’s easy to know how high or low your random values might go, since you specify a minimum and maximum number. With a normal distribution, you don’t specify starting and ending points—you specify a middle and a spread, so it’s harder to guess the whole range. Plotting random values is thus essential. Here’s 1,000 random numbers clustered around 10 with a standard deviation of 4:\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(x = rnorm(1000, mean = 10, sd = 4))\nhead(plot_data)\n## # A tibble: 6 × 1\n##        x\n##    <dbl>\n## 1  5.17 \n## 2 11.1  \n## 3 14.3  \n## 4  0.617\n## 5 11.7  \n## 6 12.0\n\nggplot(plot_data, aes(x = x)) +\n  geom_histogram(binwidth = 1, boundary = 0, color = \"white\")\n\n\n\n\n\n\n\n\n\nNeat. Most numbers are around 10; lots are between 5 and 15; some go as high as 25 and as low as −5.\nWatch what happens if you change the standard deviation to 10 to make the spread wider:\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(x = rnorm(1000, mean = 10, sd = 10))\nhead(plot_data)\n## # A tibble: 6 × 1\n##        x\n##    <dbl>\n## 1  -2.07\n## 2  12.8 \n## 3  20.8 \n## 4 -13.5 \n## 5  14.3 \n## 6  15.1\n\nggplot(plot_data, aes(x = x)) +\n  geom_histogram(binwidth = 1, boundary = 0, color = \"white\")\n\n\n\n\n\n\n\n\n\nIt’s still centered around 10, but now you get values as high as 40 and as low as −20. The data is more spread out now.\nWhen simulating data, you’ll most often use a normal distribution just because it’s easy and lots of things follow that pattern in the real world. Incomes, ages, education, etc. all have a kind of gravity to them, and a normal distribution is a good way of showing that gravity. For instance, here are 1,000 simulated people with reasonable random incomes, ages, and years of education:\n\n\nCódigo\nset.seed(1234)\n\nfake_people <- tibble(income = rnorm(1000, mean = 40000, sd = 15000),\n                      age = rnorm(1000, mean = 25, sd = 8),\n                      education = rnorm(1000, mean = 16, sd = 4))\nhead(fake_people)\n## # A tibble: 6 × 3\n##   income   age education\n##    <dbl> <dbl>     <dbl>\n## 1 21894. 15.4      12.1 \n## 2 44161. 27.4      15.6 \n## 3 56267. 12.7      15.6 \n## 4  4815. 30.1      20.8 \n## 5 46437. 30.6       9.38\n## 6 47591.  9.75     11.8\n\nfake_income <- ggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated income\")\n\nfake_age <- ggplot(fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated age\")\n\nfake_education <- ggplot(fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Simulated education\")\n\nfake_income + fake_age + fake_education\n\n\n\n\n\n\n\n\n\nThese three columns all have different centers and spreads. Income is centered around $45,000, going up to almost $100,000 and as low as −$10,000; age is centered around 25, going as low as 0 and as high as 50; education is centered around 16, going as low as 3 and as high as 28. Cool.\nAgain, when generating these numbers, it’s really hard to know how high or low these ranges will be, so it’s a good idea to plot them constantly. I settled on sd = 4 for education only because I tried things like 1 and 10 and got wild looking values (everyone basically at 16 with little variation, or everyone ranging from −20 to 50, which makes no sense when thinking about years of education). Really it’s just a process of trial and error until the data looks good and reasonable.\n\n\nTruncated normal distribution\nSometimes you’ll end up with negative numbers that make no sense. Look at income in the plot above, for instance. Some people are earning −$10,000 year. The rest of the distribution looks okay, but those negative values are annoying.\nTo fix this, you can use something called a truncated normal distribution, which lets you specify a mean and standard deviation, just like a regular normal distribution, but also lets you specify a minimum and/or maximum so you don’t get values that go too high or too low.\nR doesn’t have a truncated normal function built-in, but you can install the truncnorm package and use the rtruncnorm() function. A truncated normal distribution has four parameters:\n\nA mean (mean)\nA standard deviation (sd)\nA minimum (optional) (a)\nA maximum (optional) (b)\n\nFor instance, let’s pretend you have a youth program designed to target people who are between 12 and 21 years old, with most around 14. You can generate numbers with a mean of 14 and a standard deviation of 5, but you’ll create people who are too old, too young, or even negatively aged!\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(fake_age = rnorm(1000, mean = 14, sd = 5))\nhead(plot_data)\n## # A tibble: 6 × 1\n##   fake_age\n##      <dbl>\n## 1     7.96\n## 2    15.4 \n## 3    19.4 \n## 4     2.27\n## 5    16.1 \n## 6    16.5\n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nTo fix this, truncate the range at 12 and 21:\n\n\nCódigo\nlibrary(truncnorm)  # For rtruncnorm()\n\nset.seed(1234)\n\nplot_data <- tibble(fake_age = rtruncnorm(1000, mean = 14, sd = 5, a = 12, b = 21))\nhead(plot_data)\n## # A tibble: 6 × 1\n##   fake_age\n##      <dbl>\n## 1     15.4\n## 2     19.4\n## 3     16.1\n## 4     16.5\n## 5     14.3\n## 6     18.8\n\nggplot(plot_data, aes(x = fake_age)) +\n  geom_histogram(binwidth = 1, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nAnd voila! A bunch of people between 12 and 21, with most around 14, with no invalid values.\n\n\nBeta distribution\nNormal distributions are neat, but they’re symmetrical around the mean (unless you truncate them). What if your program involves a test with a maximum of 100 points where most people score around 85, but a sizable portion score below that. In other words, it’s not centered at 85, but is skewed left.\nTo simulate this kind of distribution, we can use a Beta distribution. Beta distributions are neat because they naturally only range between 0 and 1—they’re perfect for things like percentages or proportions or or 100-based exams.\nUnlike a normal distribution, where you use the mean and standard deviation as parameters, Beta distributions take two non-intuitive parameters:\n\nshape1\nshape2\n\nWhat the heck are these shapes though?! This answer at Cross Validated does an excellent job of explaining the intuition behind Beta distributions and it’d be worth it to read it.\nBasically, Beta distributions are good at modeling probabilities of things, and shape1 and shape2 represent specific parts of a probability formula.\nLet’s say that there’s an exam with 10 points where most people score a 6/10. Another way to think about this is that an exam is a collection of correct answers and incorrect answers, and that the percent correct follows this equation:\n\\[\n\\frac{\\text{Number correct}}{\\text{Number correct} + \\text{Number incorrect}}\n\\]\nIf you scored a 6, you could write that as:\n\\[\n\\frac{6}{6 + 4}\n\\]\nTo make it more general, we can use Greek variable names: \\(\\alpha\\) for the number correct and \\(\\beta\\) for the number incorrect, leaving us with this:\n\\[\n\\frac{\\alpha}{\\alpha + \\beta}\n\\]\nNeat.\nIn a Beta distribution, the \\(\\alpha\\) and \\(\\beta\\) in that equation correspond to shape1 and shape2. If we want to generate random scores for this test where most people get 6/10, we can use rbeta():\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(exam_score = rbeta(1000, shape1 = 6, shape2 = 4)) %>%\n  # rbeta() generates numbers between 0 and 1, so multiply everything by 10 to\n  # scale up the exam scores\n  mutate(exam_score = exam_score * 10)\n\nggplot(plot_data, aes(x = exam_score)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 0:10)\n\n\n\n\n\n\n\n\n\nMost people score around 6, with a bunch at 5 and 7, and fewer in the tails. Importantly, it’s not centered at 6—the distribution is asymmetric.\nThe magic of—and most confusing part about—Beta distributions is that you can get all sorts of curves by just changing the shape parameters. To make this easier to see, we can make a bunch of different Beta distributions. Instead of plotting them with histograms, we’ll use density plots (and instead of generating random numbers, we’ll plot the actual full range of the distribution (that’s what dbeta and geom_function() do in all these examples)).\nHere’s what we saw before, with \\(\\alpha\\) (shape1) = 6 and \\(\\beta\\) (shape2) = 4:\n\n\nCódigo\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 6, shape2 = 4))\n\n\n\n\n\n\n\n\n\nAgain, there’s a peak at 0.6 (or 6), which is what we expected.\nWe can make the distribution narrower if we scale the shapes up. Here pretty much everyone scores around 50% and 75%.\n\n\nCódigo\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 60, shape2 = 40))\n\n\n\n\n\n\n\n\n\nSo far all these curves look like normal distributions, just slightly skewed. But when if most people score 90–100%? Or most fail? A Beta distribution can handle that too:\n\n\nCódigo\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 9, shape2 = 1), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 1, shape2 = 9), color = \"red\")\n\n\n\n\n\n\n\n\n\nWith shape1 = 9 and shape2 = 1 (or \\(\\frac{9}{9 + 1}\\)) we get most around 90%, while shape1 = 1 and shape2 = 9 (or \\(\\frac{1}{1 + 9}\\)) gets us most around 10%.\nCheck out all these other shapes too:\n\n\nCódigo\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 5, shape2 = 5), color = \"blue\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5), color = \"red\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 80, shape2 = 23), color = \"orange\") +\n  geom_function(fun = ~dbeta(.x, shape1 = 13, shape2 = 17), color = \"brown\")\n\n\n\n\n\n\n\n\n\nIn real life, if I don’t want to figure out the math behind the \\(\\frac{\\alpha}{\\alpha + \\beta}\\) shape values, I end up just choosing different numbers until it looks like the shape I want, and then I use rbeta() with those parameter values. Like, how about we generate some numbers based on the red line above, with shape1 = 2 and shape2 = 5, which looks like it should be centered around 0.2ish (\\(\\frac{2}{2 + 5} = 0.2857\\)):\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(thing = rbeta(1000, shape1 = 2, shape2 = 5)) %>%\n  mutate(thing = thing * 100)\nhead(plot_data)\n## # A tibble: 6 × 1\n##   thing\n##   <dbl>\n## 1 10.1 \n## 2 34.5 \n## 3 55.3 \n## 4  2.19\n## 5 38.0 \n## 6 39.9\n\nggplot(plot_data, aes(x = thing)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nIt worked! Most values are around 20ish, but some go up to 60–80.\n\n\nBinomial distribution\nOften you’ll want to generate a column that only has two values: yes/no, treated/untreated, before/after, big/small, red/blue, etc. You’ll also likely want to control the proportions (25% treated, 62% blue, etc.). You can do this in two different ways: (1) sample() and (2) rbinom().\n\nsample()\nWe already saw sample() when we talked about uniform distributions. To generate a binary variable with sample(), just feed it a list of two possible values:\n\n\nCódigo\nset.seed(1234)\n\n# Choose 5 random T/F values\npossible_things <- c(TRUE, FALSE)\nsample(possible_things, 5, replace = TRUE)\n## [1] FALSE FALSE FALSE FALSE  TRUE\n\n\nR will choose these values with equal/uniform probability by default, but you can change that in sample() with the prob argument. For instance, pretend you want to simulate an election. According to the latest polls, one candidate has an 80% chance of winning. You want to randomly choose a winner based on that chance. Here’s how to do that with sample():\n\n\nCódigo\nset.seed(1234)\ncandidates <- c(\"Person 1\", \"Person 2\")\nsample(candidates, size = 1, prob = c(0.8, 0.2))\n## [1] \"Person 1\"\n\n\nPerson 1 wins!\nIt’s hard to see the weighted probabilities when you just choose one, so let’s pretend there are 1,000 elections:\n\n\nCódigo\nset.seed(1234)\nfake_elections <- tibble(winner = sample(candidates,\n                                         size = 1000,\n                                         prob = c(0.8, 0.2),\n                                         replace = TRUE))\nfake_elections %>%\n  count(winner)\n## # A tibble: 2 × 2\n##   winner       n\n##   <chr>    <int>\n## 1 Person 1   792\n## 2 Person 2   208\n\nggplot(fake_elections, aes(x = winner)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nPerson 1 won 792 of the elections. Neat.\n(This is essentially what election forecasting websites like FiveThirtyEight do! They just do it with way more sophisticated simulations.)\n\n\nrbinom()\nInstead of using sample(), you can use a formal distribution called the binomial distribution. This distribution is often used for things that might have “trials” or binary outcomes that are like success/failure or yes/no or true/false\nThe binomial distribution takes two parameters:\n\nsize: The number of “trials”, or times that an event happens\nprob: The probability of success in each trial\n\nIt’s easiest to see some examples of this. Let’s say you have a program that has a 60% success rate and it is tried on groups of 20 people 5 times. The parameters are thus size = 20 (since there are twenty people per group) and prob = 0.6 (since there is a 60% chance of success):\n\n\nCódigo\nset.seed(1234)\n\nrbinom(5, size = 20, prob = 0.6)\n## [1] 15 11 11 11 10\n\n\nThe results here mean that in group 1, 15/20 (75%) people had success, in group 2, 11/20 (55%) people had success, and so on. Not every group will have exactly 60%, but they’re all kind of clustered around that.\nHOWEVER, I don’t like using rbinom() like this, since this is all group-based, and when you’re generating fake people you generally want to use individuals, or groups of 1. So instead, I assume that size = 1, which means that each “group” is only one person large. This forces the generated numbers to either be 0 or 1:\n\n\nCódigo\nset.seed(1234)\n\nrbinom(5, size = 1, prob = 0.6)\n## [1] 1 0 0 0 0\n\n\nHere, only 1 of the 5 people were 1/TRUE/yes, which is hardly close to a 60% chance overall, but that’s because we only generated 5 numbers. If we generate lots, we can see the probability of yes emerge:\n\n\nCódigo\nset.seed(12345)\n\nplot_data <- tibble(thing = rbinom(2000, 1, prob = 0.6)) %>%\n  # Make this a factor since it's basically a yes/no categorical variable\n  mutate(thing = factor(thing))\n\nplot_data %>%\n  count(thing) %>%\n  mutate(proportion = n / sum(n))\n## # A tibble: 2 × 3\n##   thing     n proportion\n##   <fct> <int>      <dbl>\n## 1 0       840       0.42\n## 2 1      1160       0.58\n\nggplot(plot_data, aes(x = thing)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\n58% of the 2,000 fake people here were 1/TRUE/yes, which is close to the goal of 60%. Perfect.\n\n\n\nPoisson distribution\nOne last common distribution that you might find helpful when simulating data is the Poisson distribution (in French, “poisson” = fish, but here it’s not actually named after the animal, but after French mathematician Siméon Denis Poisson).\nA Poisson distribution is special because it generates whole numbers (i.e. nothing like 1.432) that follow a skewed pattern (i.e. more smaller values than larger values). There’s all sorts of fancy math behind it that you don’t need to worry about so much—all you need to know is that it’s good at modeling things called Poisson processes.\nFor instance, let’s say you’re sitting at the front door of a coffee shop (in pre-COVID days) and you count how many people are in each arriving group. You’ll see something like this:\n\n1 person\n1 person\n2 people\n1 person\n3 people\n2 people\n1 person\n\nLots of groups of one, some groups of two, fewer groups of three, and so on. That’s a Poisson process: a bunch of independent random events that combine into grouped events.\nThat sounds weird and esoteric (and it is!), but it reflects lots of real world phenomena, and things you’ll potentially want to measure in a program. For instance, the number of kids a family has follows a type of Poisson process. Lots of families have 1, some have 2, fewer have 3, even fewer have 4, and so on. The number of cars in traffic, the number of phone calls received by an office, arrival times in a line, and even the outbreak of wars are all examples of Poisson processes.\nYou can generate numbers from a Poisson distribution with the rpois() function in R. This distribution only takes a single parameter:\n\nlambda (\\(\\lambda\\))\n\nThe \\(\\lambda\\) value controls the rate or speed that a Poisson process increases (i.e. jumps from 1 to 2, from 2 to 3, from 3 to 4, etc.). I have absolutely zero mathematical intuition for how it works. The two shape parameters for a Beta distribution at least fit in a fraction and you can wrap your head around that, but the lambda in a Poisson distribution is just a mystery to me. So whenever I use a Poisson distribution for something, I just play with the lambda until the data looks reasonable.\nLet’s assume that the number of kids a family has follows a Poisson process. Here’s how we can use rpois() to generate that data:\n\n\nCódigo\nset.seed(123)\n\n# 10 different families\nrpois(10, lambda = 1)\n##  [1] 0 2 1 2 3 0 1 2 1 1\n\n\nCool. Most families have 0–1 kids; some have 2; one has 3.\nIt’s easier to see these patterns with a plot:\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(num_kids = rpois(500, lambda = 1))\nhead(plot_data)\n## # A tibble: 6 × 1\n##   num_kids\n##      <int>\n## 1        0\n## 2        1\n## 3        1\n## 4        1\n## 5        2\n## 6        1\n\nplot_data %>%\n  group_by(num_kids) %>%\n  summarize(count = n()) %>%\n  mutate(proportion = count / sum(count))\n## # A tibble: 6 × 3\n##   num_kids count proportion\n##      <int> <int>      <dbl>\n## 1        0   180      0.36 \n## 2        1   187      0.374\n## 3        2    87      0.174\n## 4        3    32      0.064\n## 5        4    11      0.022\n## 6        5     3      0.006\n\nggplot(plot_data, aes(x = num_kids)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nHere 75ish% of families have 0–1 kids (36% + 37.4%), 17% have 2 kids, 6% have 3, 2% have 4, and only 0.6% have 5.\nWe can play with the \\(\\lambda\\) to increase the rate of kids per family:\n\n\nCódigo\nset.seed(1234)\n\nplot_data <- tibble(num_kids = rpois(500, lambda = 2))\nhead(plot_data)\n## # A tibble: 6 × 1\n##   num_kids\n##      <int>\n## 1        0\n## 2        2\n## 3        2\n## 4        2\n## 5        4\n## 6        2\n\nplot_data %>%\n  group_by(num_kids) %>%\n  summarize(count = n()) %>%\n  mutate(proportion = count / sum(count))\n## # A tibble: 8 × 3\n##   num_kids count proportion\n##      <int> <int>      <dbl>\n## 1        0    62      0.124\n## 2        1   135      0.27 \n## 3        2   145      0.29 \n## 4        3    88      0.176\n## 5        4    38      0.076\n## 6        5    19      0.038\n## 7        6    10      0.02 \n## 8        7     3      0.006\n\nggplot(plot_data, aes(x = num_kids)) +\n  geom_bar()\n\n\n\n\n\n\n\n\n\nNow most families have 1–2 kids. Cool."
  },
  {
    "objectID": "example/random-numbers.html#rescaling-numbers",
    "href": "example/random-numbers.html#rescaling-numbers",
    "title": "Generating random numbers",
    "section": "Rescaling numbers",
    "text": "Rescaling numbers\nAll these different distributions are good at generating general shapes:\n\nUniform: a bunch of random numbers with no central gravity\nNormal: an average ± some variation\nBeta: different shapes and skews and gravities between 0 and 1\nBinomial: yes/no outcomes that follow some probability\n\nThe shapes are great, but you also care about the values of these numbers. This can be tricky. As we saw earlier with a normal distribution, sometimes you’ll get values that go below zero or above some value you care about. We fixed that with a truncated normal distribution, but not all distributions have truncated versions. Additionally, if you’re using a Beta distribution, you’re stuck in a 0–1 scale (or 0–10 or 0–100 if you multiply the value by 10 or 100 or whatever).\nWhat if you want a fun skewed Beta shape for a variable like income or some other value that doesn’t fit within a 0–1 range? You can rescale any set of numbers after-the-fact using the rescale() function from the scales library and rescale things to whatever range you want.\nFor instance, let’s say that income isn’t normally distributed, but is right-skewed with a handful of rich people. This might look like a Beta distribution with shape1 = 2 and shape2 = 5:\n\n\nCódigo\nggplot() +\n  geom_function(fun = ~dbeta(.x, shape1 = 2, shape2 = 5))\n\n\n\n\n\n\n\n\n\nIf we generate random numbers from this distribution, they’ll all be stuck between 0 and 1:\n\n\nCódigo\nset.seed(1234)\n\nfake_people <- tibble(income = rbeta(1000, shape1 = 2, shape2 = 5))\n\nggplot(fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 0.1, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nWe can take those underling 0–1 values and rescale them to some other range using the rescale() function. We can specify the minimum and maximum values in the to argument. Here we’ll scale it up so that 0 = $10,000 and 1 = $100,000. Our rescaled version follows the same skewed Beta distribution shape, but now we’re using better values!\n\n\nCódigo\nlibrary(scales)\n\nfake_people_scaled <- fake_people %>%\n  mutate(income_scaled = rescale(income, to = c(10000, 100000)))\nhead(fake_people_scaled)\n## # A tibble: 6 × 2\n##   income income_scaled\n##    <dbl>         <dbl>\n## 1 0.101         21154.\n## 2 0.345         49014.\n## 3 0.553         72757.\n## 4 0.0219        12176.\n## 5 0.380         53036.\n## 6 0.399         55162.\n\nggplot(fake_people_scaled, aes(x = income_scaled)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0)\n\n\n\n\n\n\n\n\n\nThis works for anything, really. For instance, instead of specifying a mean and standard deviation for a normal distribution and hoping that the generated values don’t go too high or too low, you can generate a normal distribution with a mean of 0 and standard deviation of 1 and then rescale it to the range you want:\n\n\nCódigo\nset.seed(1234)\n\nfake_data <- tibble(age_not_scaled = rnorm(1000, mean = 0, sd = 1)) %>%\n  mutate(age = rescale(age_not_scaled, to = c(18, 65)))\nhead(fake_data)\n## # A tibble: 6 × 2\n##   age_not_scaled   age\n##            <dbl> <dbl>\n## 1         -1.21   33.6\n## 2          0.277  44.2\n## 3          1.08   49.9\n## 4         -2.35   25.5\n## 5          0.429  45.3\n## 6          0.506  45.8\n\nplot_unscaled <- ggplot(fake_data, aes(x = age_not_scaled)) +\n  geom_histogram(binwidth = 0.5, color = \"white\", boundary = 0)\n\nplot_scaled <- ggplot(fake_data, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0)\n\nplot_unscaled + plot_scaled\n\n\n\n\n\n\n\n\n\nThis gives you less control over the center of the distribution (here it happens to be 40 because that’s in the middle of 18 and 65), but it gives you more control over the edges of the distribution.\nRescaling things is really helpful when building in effects and interacting columns with other columns, since multiplying variables by different coefficients can make the values go way out of the normal range. You’ll see a lot more of that in the synthetic data example."
  },
  {
    "objectID": "example/random-numbers.html#summary",
    "href": "example/random-numbers.html#summary",
    "title": "Generating random numbers",
    "section": "Summary",
    "text": "Summary\nPhew. We covered a lot here, and we barely scratched the surface of all the distributions that exist. Here’s a helpful summary of the main distributions you should care about:\n\n\n\n\n \n  \n    Distribution \n    Description \n    Situations \n    Parameters \n    Code \n  \n \n\n  \n    Uniform \n    Numbers between a minimum and maximum; everything equally likely \n    ID numbers, age \n    min, max \n    sample() or runif() \n  \n  \n    Normal \n    Numbers bunched up around an average with a surrounding spread; numbers closer to average more likely \n    Income, education, most types of numbers that have some sort of central tendency \n    mean, sd \n    rnorm() \n  \n  \n    Truncated normal \n    Normal distribution + constraints on minimum and/or maximum values \n    Anything with a normal distribution \n    mean, sd, a (minimum), b (maximum) \n    truncnorm::rtruncnorm() \n  \n  \n    Beta \n    Numbers constrained between 0 and 1 \n    Anything with percents; anything on a 0–1(00) scale; anything, really, if you use rescale() to rescale it \n    shape1 ($\\alpha$), shape2 ($\\beta$) ($\\frac{\\alpha}{\\alpha + \\beta}$) \n    rbeta() \n  \n  \n    Binomial \n    Binary variables \n    Treatment/control, yes/no, true/false, 0/1 \n    size, prob \n    sample(..., prob = 0.5) or rbinom() \n  \n  \n    Poisson \n    Whole numbers that represent counts of things \n    Number of kids, number of cities lived in, arrival times \n    lambda \n    rpois()"
  },
  {
    "objectID": "example/random-numbers.html#example",
    "href": "example/random-numbers.html#example",
    "title": "Generating random numbers",
    "section": "Example",
    "text": "Example\nAnd here’s an example dataset of 1,000 fake people and different characteristics. One shortcoming of this fake data is that each of these columns is completely independent—there’s no relationship between age and education and family size and income. You can see how to make these columns correlated (and make one cause another!) in the example for synthetic data.\n\n\nCódigo\nset.seed(1234)\n\n# Set the number of people here once so it's easier to change later\nn_people <- 1000\n\nexample_fake_people <- tibble(\n  id = 1:n_people,\n  opinion = sample(1:5, n_people, replace = TRUE),\n  age = runif(n_people, min = 18, max = 80),\n  income = rnorm(n_people, mean = 50000, sd = 10000),\n  education = rtruncnorm(n_people, mean = 16, sd = 6, a = 8, b = 24),\n  happiness = rbeta(n_people, shape1 = 2, shape2 = 1),\n  treatment = sample(c(TRUE, FALSE), n_people, replace = TRUE, prob = c(0.3, 0.7)),\n  size = rbinom(n_people, size = 1, prob = 0.5),\n  family_size = rpois(n_people, lambda = 1) + 1  # Add one so there are no 0s\n) %>%\n  # Adjust some of these columns\n  mutate(opinion = recode(opinion, \"1\" = \"Strongly disagree\",\n                          \"2\" = \"Disagree\", \"3\" = \"Neutral\",\n                          \"4\" = \"Agree\", \"5\" = \"Strongly agree\")) %>%\n  mutate(size = recode(size, \"0\" = \"Small\", \"1\" = \"Large\")) %>%\n  mutate(happiness = rescale(happiness, to = c(1, 8)))\n\nhead(example_fake_people)\n## # A tibble: 6 × 9\n##      id opinion             age income education happiness treatment size  family_size\n##   <int> <chr>             <dbl>  <dbl>     <dbl>     <dbl> <lgl>     <chr>       <dbl>\n## 1     1 Agree              31.7 43900.      18.3      7.20 TRUE      Large           1\n## 2     2 Disagree           52.9 34696.      17.1      4.73 TRUE      Large           2\n## 3     3 Strongly agree     45.3 43263.      17.1      7.32 FALSE     Large           4\n## 4     4 Agree              34.9 40558.      11.7      4.18 FALSE     Small           2\n## 5     5 Strongly disagree  50.3 41392.      13.3      2.61 TRUE      Small           2\n## 6     6 Strongly agree     63.6 69917.      11.2      4.36 FALSE     Small           2\n\n\n\n\nCódigo\nplot_opinion <- ggplot(example_fake_people, aes(x = opinion)) +\n  geom_bar() +\n  guides(fill = \"none\") +\n  labs(title = \"Opinion (uniform with sample())\")\n\nplot_age <- ggplot(example_fake_people, aes(x = age)) +\n  geom_histogram(binwidth = 5, color = \"white\", boundary = 0) +\n  labs(title = \"Age (uniform with runif())\")\n\nplot_income <- ggplot(example_fake_people, aes(x = income)) +\n  geom_histogram(binwidth = 5000, color = \"white\", boundary = 0) +\n  labs(title = \"Income (normal)\")\n\nplot_education <- ggplot(example_fake_people, aes(x = education)) +\n  geom_histogram(binwidth = 2, color = \"white\", boundary = 0) +\n  labs(title = \"Education (truncated normal)\")\n\nplot_happiness <- ggplot(example_fake_people, aes(x = happiness)) +\n  geom_histogram(binwidth = 1, color = \"white\") +\n  scale_x_continuous(breaks = 1:8) +\n  labs(title = \"Happiness (Beta, rescaled to 1-8)\")\n\nplot_treatment <- ggplot(example_fake_people, aes(x = treatment)) +\n  geom_bar() +\n  labs(title = \"Treatment (binary with sample())\")\n\nplot_size <- ggplot(example_fake_people, aes(x = size)) +\n  geom_bar() +\n  labs(title = \"Size (binary with rbinom())\")\n\nplot_family <- ggplot(example_fake_people, aes(x = family_size)) +\n  geom_bar() +\n  scale_x_continuous(breaks = 1:7) +\n  labs(title = \"Family size (Poisson)\")\n\n(plot_opinion + plot_age) / (plot_income + plot_education)\n\n\n\n\n\n\n\n\n\n\n\nCódigo\n(plot_happiness + plot_treatment) / (plot_size + plot_family)"
  },
  {
    "objectID": "example/rstudio-tidyverse.html",
    "href": "example/rstudio-tidyverse.html",
    "title": "R, RStudio, and the tidyverse",
    "section": "",
    "text": "For this week’s problem set, you need to work through a few of RStudio’s introductory primers. You’ll do these in your browser and type code and see results there.\nYou’ll learn some of the basics of R, as well as some powerful methods for manipulating data with the dplyr package.\nComplete these primers. It seems like there are a lot, but they’re short and go fairly quickly (especially as you get the hang of the syntax). Also, I have no way of seeing what you do or what you get wrong or right, and that’s totally fine! If you get stuck and want to skip some (or if it gets too easy), go right ahead and skip them!\n\nThe Basics\n\nVisualization Basics\nProgramming Basics\n\nWork with Data\n\nWorking with Tibbles\nIsolating Data with dplyr\nDeriving Information with dplyr\n\nVisualize Data\n\nExploratory Data Analysis\nBar Charts\nHistograms\nBoxplots and Counts\nScatterplots\nLine plots\nOverplotting and Big Data\nCustomize Your Plots\n\nTidy Your Data\n\nReshape Data\n\n\n\n\n\n\n\n\nNota\n\n\n\nRecent versions of tidyr have renamed these core functions: gather() is now pivot_longer() and spread() is now pivot_wider(). The syntax for these pivot_*() functions is slightly different from what it was in gather() and spread(), so you can’t just replace the names. Fortunately, both gather() and spread() still work and won’t go away for a while, so you can still use them as you learn about reshaping and tidying data. It would be worth learning how the newer pivot_*() functions work, eventually, though (see here for examples).\n\n\nThe content from these primers comes from the (free and online!) book R for Data Science by Garrett Grolemund and Hadley Wickham. I highly recommend the book as a reference and for continuing to learn and use R in the future."
  },
  {
    "objectID": "example/rstudio-tidyverse.html#part-2-getting-familiar-with-rstudio",
    "href": "example/rstudio-tidyverse.html#part-2-getting-familiar-with-rstudio",
    "title": "R, RStudio, and the tidyverse",
    "section": "Part 2: Getting familiar with RStudio",
    "text": "Part 2: Getting familiar with RStudio\nThe RStudio primers you just worked through are a great introduction to writing and running R code, but you typically won’t type code in a browser when you work with R. Instead, you’ll use a nicer programming environment like RStudio, which lets you type and save code in scripts, run code from those scripts, and see the output of that code, all in the same program.\nTo get familiar with RStudio, watch this video (it’s from PMAP 8921, but the content still applies here):"
  },
  {
    "objectID": "example/rstudio-tidyverse.html#part-3-rstudio-projects",
    "href": "example/rstudio-tidyverse.html#part-3-rstudio-projects",
    "title": "R, RStudio, and the tidyverse",
    "section": "Part 3: RStudio Projects",
    "text": "Part 3: RStudio Projects\nOne of the most powerful and useful aspects of RStudio is its ability to manage projects.\nWhen you first open R, it is “pointed” at some folder on your computer, and anything you do will be relative to that folder. The technical term for this is a “working directory.”\nWhen you first open RStudio, look in the area right at the top of the Console pane to see your current working directory. Most likely you’ll see something cryptic: ~/\n\n\n\n\n\nThat tilde sign (~) is a shortcut that stands for your user directory. On Windows this is C:\\Users\\your_user_name\\; on macOS this is /Users/your_user_name/. With the working directory set to ~/, R is “pointed” at that folder, and anything you save will end up in that folder, and R will expect any data that you load to be there too.\nIt’s always best to point R at some other directory. If you don’t use RStudio, you need to manually set the working directory to where you want it with setwd(), and many R scripts in the wild include something like setwd(\"C:\\\\Users\\\\bill\\\\Desktop\\\\Important research project\") at the beginning to change the directory. THIS IS BAD THOUGH (see here for an explanation). If you ever move that directory somewhere else, or run the script on a different computer, or share the project with someone, the path will be wrong and nothing will run and you will be sad.\nThe best way to deal with working directories with RStudio is to use RStudio Projects. These are special files that RStudio creates for you that end in a .Rproj extension. When you open one of these special files, a new RStudio instance will open up and be pointed at the correct directory automatically. If you move the folder later or open it on a different computer, it will work just fine and you will not be sad.\nRead this super short chapter on RStudio projects to learn how to create and use them\nIn general, you can create a new project by going to File > New Project > New Directory > Empty Project, which will create a new folder on your computer that is empty except for a single .Rproj file. Double click on that file to open an RStudio instance that is pointed at the correct folder."
  },
  {
    "objectID": "example/rstudio-tidyverse.html#part-4-getting-familiar-with-r-markdown",
    "href": "example/rstudio-tidyverse.html#part-4-getting-familiar-with-r-markdown",
    "title": "R, RStudio, and the tidyverse",
    "section": "Part 4: Getting familiar with R Markdown",
    "text": "Part 4: Getting familiar with R Markdown\nTo ensure that the analysis and graphics you make are reproducible, you’ll do the majority of your work in this class using R Markdown files.\nDo the following things:\n\nWatch this video:\n\n\n\n\n\n \n\nSkim through the content at these pages:\n\nUsing Markdown\nUsing R Markdown\nHow it Works\nCode Chunks\nInline Code\nMarkdown Basics (The R Markdown Reference Guide is super useful here.)\nOutput Formats\n\nWatch this video (again, it’s from PMAP 8921, but the content works for this class):"
  },
  {
    "objectID": "example/standard-errors.html",
    "href": "example/standard-errors.html",
    "title": "Robust and clustered standard errors with R",
    "section": "",
    "text": "As you read in chapter 13.3 of The Effect, your standard errors in regressions are probably wrong. And as you read in the article by Guido Imbens, we want accurate standard errors because we should be focusing on confidence intervals when reporting our findings because nobody actually cares about or understands p-values.\nSo why are our standard errors wrong, and how do we fix them?\nFirst, let’s make a model that predicts penguin weight based on bill length, flipper length, and species. We’ll use our regular old trusty lm() for an OLS model with regular standard errors.\nA 1 mm increase in bill length is associated with a 60.1 g increase in penguin weight, on average. This is significantly significant and different from zero (p < 0.001), and the confidence interval ranges between 45.9 and 74.3, which means that we’re 95% confident that this range captures the true population parameter (this is a frequentist interval since we didn’t do any Bayesian stuff, so we have to talk about the confidence interval like a net and use awkward language).\nThis confidence interval is the coefficient estimate ± (1.96 × the standard error) (or 60.1 ± (1.96 × 7.21)), so it’s entirely dependent on the accuracy of the standard error. One of the assumptions of this estimate and its corresponding standard error is that the residuals of the regression (i.e. the distance from the predicted values and the actual values—remember this plot from Session 2) must not have any patterns in them. The official name for this assumption is that the errors in an OLS must be homoskedastic (or exhibit homoskedasticity). If errors are heteroskedastic—if the errors aren’t independent from each other, if they aren’t normally distributed, and if there are visible patterns in them—your standard errors (and confidence intervals) will be wrong."
  },
  {
    "objectID": "example/standard-errors.html#checking-for-heteroskedasticity",
    "href": "example/standard-errors.html#checking-for-heteroskedasticity",
    "title": "Robust and clustered standard errors with R",
    "section": "Checking for heteroskedasticity",
    "text": "Checking for heteroskedasticity\nHow do you know if your errors are homoskedastic of heterosketastic though?\nThe easiest way for me (and most people probably) is to visualize the residuals and see if there are any patterns. First, we can use augment() to calculate the residuals for each observation in the original penguin data and then make a scatterplot that puts the actual weight on the x-axis and the residuals on the y-axis.\n\n\nCódigo\n# Plug the original data into the model and find fitted values and\n# residuals/errors\nfitted_data <- augment(model1, data = penguins)\n\n# Look at relationship between fitted values and residuals\nggplot(fitted_data, aes(x = .fitted, y = .resid)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nThere seems to be two clusters of points here, which is potentially a sign that the errors aren’t independent of each other—there might be a systematic pattern in the errors. We can confirm this if we color the points by species:\n\n\nCódigo\nggplot(fitted_data, aes(x = .fitted, y = .resid)) + \n  geom_point(aes(color = species)) +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nAnd there are indeed species-based clusters within the residuals! We can see this if we look at the distribution of the residuals too. For OLS assumptions to hold—and for our standard errors to be correct—this should be normally distributed:\n\n\nCódigo\nggplot(fitted_data, aes(x = .resid)) +\n  geom_histogram(binwidth = 100, color = \"white\", boundary = 3000)\n\n\n\n\n\n\n\n\n\nThis looks fairly normal, though there are some more high residual observations (above 500) than we’d expect. That’s likely because the data isn’t actually heteroskedastic—it’s just clustered, and this clustering structure within the residuals means that our errors (and confidence intervals and p-values) are going to be wrong.\nIn this case the residual clustering creates a fairly obvious pattern. Just for fun, let’s ignore the Gentoos and see what residuals without clustering can look like. The residuals here actually look fairly random and pattern-free:\n\n\nCódigo\nmodel_no_gentoo <- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species,\n                      data = filter(penguins, species != \"Gentoo\"))\n\nfitted_sans_gentoo <- augment(model_no_gentoo,\n                              filter(penguins, species != \"Gentoo\"))\n\nggplot(fitted_sans_gentoo, aes(x = .fitted, y = .resid)) + \n  geom_point() +\n  geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\n\nWe can do a neat little visual test for this. Let’s shuffle the residuals a bunch of times and make scatterplots with those shuffled values. If we can’t spot the actual residual plot among the shuffled ones, we can be fairly confident that there aren’t any patterns. The nullabor package makes this easy, allowing us to create a lineup of shuffled plots with the real residual plot mixed in there somewhere.\n\n\nCódigo\nlibrary(nullabor)\n\nset.seed(1234)  # Shuffle these the same way every time\n\nshuffled_residuals <- lineup(null_lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species,\n                                     method = \"rotate\"),\n                             true = fitted_sans_gentoo,\n                             n = 9)\n## decrypt(\"D6OW f9c9 VZ pzQVcVzZ yy\")\n\nggplot(shuffled_residuals, aes(x = .fitted, y = .resid)) +\n  geom_point() +\n  facet_wrap(vars(.sample))\n\n\n\n\n\n\n\n\n\nWhich one is the actual residual plot? There’s no easy way to tell. That cryptic decrypt(...) thing is a special command that will tell us which plot is the correct one:\n\n\nCódigo\ndecrypt(\"sD0f gCdC En JP2EdEPn ZZ\")\n## Warning in decrypt(\"sD0f gCdC En JP2EdEPn ZZ\"): NAs introducidos por coerción\n## [1] \"MTQd qE3E b8 jvlb3bv8  NA\"\n\n\nThe fact that we can’t tell is a good sign that the residuals are homoskedastic and independent and that we don’t need to worry much about correcting the errors."
  },
  {
    "objectID": "example/standard-errors.html#adjusting-standard-errors",
    "href": "example/standard-errors.html#adjusting-standard-errors",
    "title": "Robust and clustered standard errors with R",
    "section": "Adjusting standard errors",
    "text": "Adjusting standard errors\nHowever, often you will see patterns or clusters in the residuals, which means you need to make some adjustments to the errors to ensure they’re accurate. In chapter 13.3 of The Effect you read about a bunch of different mathy ways to make these adjustments, and people get PhDs and write whole dissertations on new fancy ways to adjust standard errors. I’m not super interested in the deeper mathy mechanics of error adjustment, and most people aren’t either, so statistical software packages generally try to make it easy to make these adjustments without needing to think about the deeper math.\nIf you’re familiar with Stata, you can get robust standard errors like this:\n# Run this in R first to export the penguins data as a CSV\nwrite_csv(\"~/Desktop/penguins.csv\")\n/* Stata stuff */\n\nimport delimited \"~/Desktop/penguins.csv\", clear \n\nencode species, generate(species_f)  /* Make species a factor /*\n\nreg body_mass_g bill_length_mm flipper_length_mm i.species_f, robust\n\n/* \nLinear regression                               Number of obs     =        333\n                                                F(4, 328)         =     431.96\n                                                Prob > F          =     0.0000\n                                                R-squared         =     0.8243\n                                                Root MSE          =     339.57\n-----------------------------------------------------------------------------------\n                  |               Robust\n      body_mass_g |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n------------------+----------------------------------------------------------------\n   bill_length_mm |   60.11733   6.429263     9.35   0.000     47.46953    72.76512\nflipper_length_mm |   27.54429   3.054304     9.02   0.000     21.53579    33.55278\n                  |\n        species_f |\n       Chinstrap  |  -732.4167     75.396    -9.71   0.000    -880.7374    -584.096\n          Gentoo  |   113.2541   88.27028     1.28   0.200    -60.39317    286.9014\n                  |\n            _cons |  -3864.073   500.7276    -7.72   0.000    -4849.116   -2879.031\n----------------------------------------------------------------------------------- \n*/\nAnd you can get clustered robust standard errors like this:\nreg body_mass_g bill_length_mm flipper_length_mm i.species_f, cluster(species_f)\n\n/*\nLinear regression                               Number of obs     =        333\n                                                F(1, 2)           =          .\n                                                Prob > F          =          .\n                                                R-squared         =     0.8243\n                                                Root MSE          =     339.57\n                                   (Std. Err. adjusted for 3 clusters in species_f)\n-----------------------------------------------------------------------------------\n                  |               Robust\n      body_mass_g |      Coef.   Std. Err.      t    P>|t|     [95% Conf. Interval]\n------------------+----------------------------------------------------------------\n   bill_length_mm |   60.11733   12.75121     4.71   0.042     5.253298    114.9814\nflipper_length_mm |   27.54429   4.691315     5.87   0.028     7.359188    47.72939\n                  |\n        species_f |\n       Chinstrap  |  -732.4167   116.6653    -6.28   0.024    -1234.387   -230.4463\n          Gentoo  |   113.2541   120.5977     0.94   0.447    -405.6361    632.1444\n                  |\n            _cons |  -3864.073   775.9628    -4.98   0.038    -7202.772   -525.3751\n-----------------------------------------------------------------------------------\n*/\nBasically add , robust (or even just ,r) or cluster(whatever) to the end of the regression command.\nDoing this in R is a little trickier since our favorite standard lm() command doesn’t have built-in support for robust or clustered standard errors, but there are some extra packages that make it really easy to do. Let’s look at three different ways.\n\nsandwich and coeftest()\nOne way to adjust errors is to use the sandwich package, which actually handles the standard error correction behind the scenes for most of the other approaches we’ll look at. sandwich comes with a bunch of standard error correction functions, like vcovHC() for heteroskedasticity-consistent (HC) errors, vcovHAC() for heteroskedastiticy- and autocorrelation-consistent (HAC) errors, and vcovCL() for clustered errors (see their website for all the different ones). Within each of these different functions, there are different types (again, things that fancy smart statisticians figure out). If you want to replicate Stata’s , robust option exactly, you can use vcovHC(type = \"HC1\").\nYou can use these correction functions as an argument to the coeftest() function, the results of which conveniently work with tidy() and other broom functions. Here’s how we can get robust standard errors for our original penguin model (model1):\n\n\nCódigo\nlibrary(sandwich)  # Adjust standard errors\nlibrary(lmtest)    # Recalculate model errors with sandwich functions with coeftest()\n\n# Robust standard errors with lm()\nmodel1_robust <- coeftest(model1, \n                          vcov = vcovHC)\n\n# Stata's robust standard errors with lm()\nmodel1_robust_stata <- coeftest(model1, \n                                vcov = vcovHC,\n                                type = \"HC1\")\n\ntidy(model1_robust) %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 bill_length_mm     60.1      6.52      9.22 3.67e-18\n\ntidy(model1_robust_stata) %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 bill_length_mm     60.1      6.43      9.35 1.40e-18\n\n\nThose errors shrunk a little, likely because just using robust standard errors here isn’t enough. Remember that there are clear clusters in the residuals (Gentoo vs. not Gentoo), so we’ll actually want to cluster the errors by species. vcovCL() lets us do that:\n\n\nCódigo\n# Clustered robust standard errors with lm()\nmodel1_robust_clustered <- coeftest(model1,\n                                    vcov = vcovCL,\n                                    type = \"HC1\",\n                                    cluster = ~species)\n\ntidy(model1_robust_clustered, conf.int = TRUE) %>% \n  filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 7\n##   term           estimate std.error statistic    p.value conf.low conf.high\n##   <chr>             <dbl>     <dbl>     <dbl>      <dbl>    <dbl>     <dbl>\n## 1 bill_length_mm     60.1      12.8      4.71 0.00000359     35.0      85.2\n\n\nThose errors are huge now, and the confidence interval ranges from 35 to 85! That’s because we’re now accounting for the clustered structure in the errors.\nBut we’re still not getting the same results as the clustered robust errors from Stata (or as feols() and lm_robust() below). This is because the data we’re working with here has a small number of clusters and coeftest()/vcovCL() doesn’t deal with that automatically (but Stata, feols(), and lm_robust() all do—see this section about it in the documentation for feols()). To fix this, we need to specify the number of degrees of freedom in the coeftest() function. There are three species/clusters in this data, so the degrees of freedom is 1 less than that, or 2.\n\n\nCódigo\n# Clustered robust standard errors with lm(), correcting for small sample\nmodel1_robust_clustered_corrected <- coeftest(model1,\n                                              vcov = vcovCL,\n                                              type = \"HC1\",\n                                              df = 2,  # There are 3 species, so 3-1 = 2\n                                              cluster = ~species)\n\ntidy(model1_robust_clustered_corrected, conf.int = TRUE) %>% \n  filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 7\n##   term           estimate std.error statistic p.value conf.low conf.high\n##   <chr>             <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n## 1 bill_length_mm     60.1      12.8      4.71  0.0422     5.25      115.\n\n\nThere we go. Now we have absolutely massive confidence intervals ranging from 5 to 115. Who even knows what the true parameter is?! Our net probably caught it.\n\n\nfixest and feols()\nStandard error adjustment with the functions from sandwich and coeftest() works fine, but it requires multiple steps: (1) create a model with lm(), and (2) feed that model to coeftest(). It would be great if we could do that all at the same time in one command! Fortunately there are a few R packages that let us do this.\nThe feols() function from the fixest package was designed for OLS models that have lots of fixed effects (i.e. indicator variables), and it handles lots of fixed effects really really fast. It can also handle instrumental variables (which we’ll get to later in the semester). It’s a fantastic way to run models in R. It uses the same formula syntax as lm(), but with one extra feature: you can put fixed effects (again, indicator variables) after a | to specify that the variables are actually fixed effects. This (1) speeds up model estimation, and (2) hides the fixed effects from summary() and tidy() output, which is super convenient if you’re using something like county, state, or country fixed effects and you don’t want to see dozens or hundreds of extra rows in the regression output.\nIt includes an argument vcov for specifying how you want to handle the standard errors, and you can use lots of different options. Here we’ll make two models: one with heteroskedastic robust SEs (basically what Stata uses, or like vcovHC() in sandwich), and one with clustered robust standard errors (similar to vcovCL() in sandwich):\n\n\nCódigo\nlibrary(fixest)  # Run models with feols()\n\n# Because species comes after |, it's being treated as a fixed effect\nmodel_feols_hetero <- feols(body_mass_g ~ bill_length_mm + flipper_length_mm | species,\n                            vcov = \"hetero\",\n                            data = penguins)\n\ntidy(model_feols_hetero) %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 bill_length_mm     60.1      6.43      9.35 1.40e-18\n\nmodel_feols_clustered <- feols(body_mass_g ~ bill_length_mm + flipper_length_mm | species,\n                               cluster = ~ species,\n                               data = penguins)\n\ntidy(model_feols_clustered, conf.int = TRUE) %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 7\n##   term           estimate std.error statistic p.value conf.low conf.high\n##   <chr>             <dbl>     <dbl>     <dbl>   <dbl>    <dbl>     <dbl>\n## 1 bill_length_mm     60.1      12.7      4.73  0.0419     5.42      115.\n\n\nWe get basically the same standard errors we did before with coeftest(lm(), vcov = ...), only now we did it all in one step.\n\n\nestimatr and lm_robust()\nThe lm_robust() function in the estimatr package also allows you to calculate robust standard errors in one step using the se_type argument. See the documentation for all the possible options. Here we can replicate Stata’s standard errors by using se_type = \"stata\" (se_type = \"HC1\" would do the same thing). lm_robust() also lets you specify fixed effects separately so that they’re hidden in the results, but instead of including them in the formula like we did with feols(), we have to use the fixed_effects argument.\n\n\nCódigo\nlibrary(estimatr)  # Run models with lm_robust()\n\nmodel_lmrobust_clustered <- lm_robust(body_mass_g ~ bill_length_mm + flipper_length_mm,\n                                      fixed_effects = ~ species,\n                                      se_type = \"stata\",\n                                      clusters = species,\n                                      data = penguins)\n\ntidy(model_lmrobust_clustered, conf.int = TRUE) %>% filter(term == \"bill_length_mm\")\n##             term estimate std.error statistic p.value conf.low conf.high df     outcome\n## 1 bill_length_mm       60        13       4.7   0.042      5.3       115  2 body_mass_g\n\n\n\n\nOn-the-fly SE adjustment\nWhile it’s neat that we can specify standard errors directly in feols() and lm_robust(), it’s sometimes (almost always) a good idea to actually not adjust SEs within the models themselves and instead make the adjustments after you’ve already fit the model. This is especially the case if you have a more complex model that takes a while to run. Note how we ran a couple different feols() models previously—it would be nice if we could just run the model once and then choose whatever standard error adjustments we want later. This is what we already did with coeftest(model, vcov = ...). We can do similar things with feols(). Watch how we can specify the standard error options and clusters inside tidy() directly, with just one model!\n\n\nCódigo\nmodel_feols_basic <- feols(body_mass_g ~ bill_length_mm + flipper_length_mm | species,\n                           data = penguins)\n\ntidy(model_feols_basic, se = \"hetero\") %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 5\n##   term           estimate std.error statistic  p.value\n##   <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n## 1 bill_length_mm     60.1      6.43      9.35 1.40e-18\n\ntidy(model_feols_basic, cluster = \"species\") %>% filter(term == \"bill_length_mm\")\n## # A tibble: 1 × 5\n##   term           estimate std.error statistic p.value\n##   <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n## 1 bill_length_mm     60.1      12.7      4.73  0.0419\n\n\nThe modelsummary() function from the modelsummary package also lets us make SE adjustments on the fly. Check this out—with just one basic model with lm(), we can get all these different kinds of standard errors!\n\n\nCódigo\nlibrary(modelsummary)  # Make nice tables and plots for models\n\nmodel_basic <- lm(body_mass_g ~ bill_length_mm + flipper_length_mm + species,\n                  data = penguins)\n\n# Add an extra row with the error names\nse_info <- tibble(term = \"Standard errors\", \"Regular\", \"Robust\", \"Stata\", \"Clustered by species\")\n\nmodelsummary(model_basic, \n             # Specify how to robustify/cluster the model\n             vcov = list(\"iid\", \"robust\", \"stata\", function(x) vcovCL(x, cluster = ~ species)),\n             # Get rid of other coefficients and goodness-of-fit (gof) stats\n             coef_omit = \"species|flipper|Intercept\", gof_omit = \".*\",\n             add_rows = se_info)\n\n\n\n\n \n  \n      \n    Model 1 \n    Model 2 \n    Model 3 \n    Model 4 \n  \n \n\n  \n    bill_length_mm \n    60.117 \n    60.117 \n    60.117 \n    60.117 \n  \n  \n     \n    (7.207) \n    (6.519) \n    (6.429) \n    (12.751) \n  \n  \n    Standard errors \n    Regular \n    Robust \n    Stata \n    Clustered by species \n  \n\n\n\n\n\n\n\nPlot all these confidence intervals\nThe modelsummary package also comes with a modelplot() function that will create a coefficient plot showing the point estimates and 95% confidence intervals. Look at all these different standard errors!\n\n\nCódigo\nmodelplot(\n  list('lm_robust(se_type = \"stata\", clusters = species)' = model_lmrobust_clustered,\n       'feols(se = \"cluster\", cluster = ~species)' = model_feols_clustered,\n       'feols(se = \"hetero\")' = model_feols_hetero,\n       'lm() + vcovCL(cluster = \"species\") [small sample corrected]' = model1_robust_clustered_corrected,\n       'lm() + vcovCL(cluster = \"species\")' = model1_robust_clustered,\n       'lm() + vcovHC(type = \"HC1\") [Stata]' = model1_robust_stata,\n       \"lm() + vcovHC() [robust]\" = model1_robust,\n       \"Basic lm() model\" = model1),\n  coef_omit = \"species|flipper|Intercept\") + \n  guides(color = guide_legend(reverse = TRUE))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "R para Ciencia de Datos en Salud 3",
    "section": "",
    "text": "Instructor\n\n   Percy Soto-Becerra, M.D., M.Sc(c)\n   Virtual: Vimeo & Google Meet\n   percys1991@gmail.com\n   psotob91\n   Agenda una reunión virtual\n\n\n\nDetalles del curso\n\n   Sábados\n   06 de agosto a 25 de setiembre, 2022\n   Asincrónico: Sábados 3 pm   Sincrónico: Martes o Jueves\n   Asincrónico: Vimeo   Sincrónico: Google Meet\n   Discord\n\n\n\nContáctame\nE-mail y Discord son las mejores formas de ponerse en contacto conmigo. Intentaré responder a todos los correos electrónicos relacionados con el curso y los mensajes de Discord dentro de las 24 horas (de verdad), pero también recuerde que la vida puede ser ajetreada y caótica para todos (¡incluido yo!), así que si no respondo enseguida, no te preocupes!"
  },
  {
    "objectID": "resource/citations.html",
    "href": "resource/citations.html",
    "title": "Citations and bibliography",
    "section": "",
    "text": "references.bib\n\nYou can open the file in BibDesk on macOS, JabRef on Windows, or Zotero or Mendeley online."
  },
  {
    "objectID": "resource/data.html",
    "href": "resource/data.html",
    "title": "Data",
    "section": "",
    "text": "Data is Plural newsletter: Jeremy Singer-Vine sends a weekly newsletter of the most interesting public datasets he’s found. You should subscribe to it. He also has an archive of all the datasets he’s highlighted.\nGoogle Dataset Search: Google indexes thousands of public datasets; search for them here.\nKaggle: Kaggle hosts machine learning competitions where people compete to create the fastest, most efficient, most predictive algorithms. A byproduct of these competitions is a host of fascinating datasets that are generally free and open to the public. See, for example, the European Soccer Database, the Salem Witchcraft Dataset or results from an Oreo flavors taste test.\n360Giving: Dozens of British foundations follow a standard file format for sharing grant data and have made that data available online.\nUS City Open Data Census: More than 100 US cities have committed to sharing dozens of types of data, including data about crime, budgets, campaign finance, lobbying, transit, and zoning. This site from the Sunlight Foundation and Code for America collects this data and rates cities by how well they’re doing.\nPolitical science and economics datasets: There’s a wealth of data available for political science- and economics-related topics:\n\nFrançois Briatte’s extensive curated lists: Includes data from/about intergovernmental organizations (IGOs), nongovernmental organizations (NGOs), public opinion surveys, parliaments and legislatures, wars, human rights, elections, and municipalities.\nThomas Leeper’s list of political science datasets: Good short list of useful datasets, divided by type of data (country-level data, survey data, social media data, event data, text data, etc.).\nErik Gahner’s list of political science datasets: Huge list of useful datasets, divided by topic (governance, elections, policy, political elites, etc.)"
  },
  {
    "objectID": "resource/index.html",
    "href": "resource/index.html",
    "title": "Recursos adicionales",
    "section": "",
    "text": "En esta sección trataremos de incluir un montón de recursos y guías adicionales relacionadas con análisis descriptivo e inferencia. ¡Hagan sus solicitudes por Discord!"
  },
  {
    "objectID": "resource/install.html",
    "href": "resource/install.html",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "",
    "text": "You will do all of your work in this class with the open source (and free!) programming language R. You will use RStudio as the main program to access R. Think of R as an engine and RStudio as a car dashboard—R handles all the calculations and the actual statistics, while RStudio provides a nice interface for running R code."
  },
  {
    "objectID": "resource/install.html#rstudio.cloud",
    "href": "resource/install.html#rstudio.cloud",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "RStudio.cloud",
    "text": "RStudio.cloud\nR is free, but it can sometimes be a pain to install and configure. To make life easier, you can (and should!) use the free RStudio.cloud service initially, which lets you run a full instance of RStudio in your web browser. This means you won’t have to install anything on your computer to get started with R! We will have a shared class workspace in RStudio.cloud that will let you quickly copy templates for labs and problem sets.\nGo to https://rstudio.cloud/ and create an account. You’ll receive a link to join the shared class workspace separately. If you don’t get this link, let me know and I will invite you."
  },
  {
    "objectID": "resource/install.html#rstudio-on-your-computer",
    "href": "resource/install.html#rstudio-on-your-computer",
    "title": "Installing R, RStudio, tidyverse, and tinytex",
    "section": "RStudio on your computer",
    "text": "RStudio on your computer\nRStudio.cloud is convenient, but it can be slow and it is not designed to be able to handle larger datasets, more complicated analysis, or fancier graphics. Over the course of the semester, you should wean yourself off of RStudio.cloud and install all these things locally. This is also important if you want to customize fonts, since RStudio.cloud has extremely limited support for fonts other than Helvetica.\nHere’s how you install all these things\n\nInstall R\nFirst you need to install R itself (the engine).\n\nGo to the CRAN (Collective R Archive Network)1 website: https://cran.r-project.org/\nClick on “Download R for XXX”, where XXX is either Mac or Windows:\n::: {.cell} ::: {.cell-output-display}  ::: :::\n\nIf you use macOS, scroll down to the first .pkg file in the list of files (in this picture, it’s R-4.0.0.pkg; as of right now, the current version is also 4.0.0) and download it.\n::: {.cell} ::: {.cell-output-display}  ::: :::\nIf you use Windows, click “base” (or click on the bolded “install R for the first time” link) and download it.\n::: {.cell} ::: {.cell-output-display}  ::: :::\n\nDouble click on the downloaded file (check your Downloads folder). Click yes through all the prompts to install like any other program.\nIf you use macOS, download and install XQuartz. You do not need to do this on Windows.\n\n\n\nInstall RStudio\nNext, you need to install RStudio, the nicer graphical user interface (GUI) for R (the dashboard). Once R and RStudio are both installed, you can ignore R and only use RStudio. RStudio will use R automatically and you won’t ever have to interact with it directly.\n\nGo to the free download location on RStudio’s website: https://www.rstudio.com/products/rstudio/download/#download\nThe website should automatically detect your operating system (macOS or Windows) and show a big download button for it:\n::: {.cell} ::: {.cell-output-display}  ::: :::\nIf not, scroll down a little to the large table and choose the version of RStudio that matches your operating system.\n::: {.cell} ::: {.cell-output-display}  ::: :::\nDouble click on the downloaded file (again, check your Downloads folder). Click yes through all the prompts to install like any other program.\n\nDouble click on RStudio to run it (check your applications folder or start menu).\n\n\nInstall tidyverse\nR packages are easy to install with RStudio. Select the packages panel, click on “Install,” type the name of the package you want to install, and press enter.\n\n\n\n\n\nThis can sometimes be tedious when you’re installing lots of packages, though. The tidyverse, for instance, consists of dozens of packages (including ggplot2) that all work together. Rather than install each individually, you can install a single magical package and get them all at the same time.\nGo to the packages panel in RStudio, click on “Install,” type “tidyverse”, and press enter. You’ll see a bunch of output in the RStudio console as all the tidyverse packages are installed.\n\n\n\n\n\nNotice also that RStudio will generate a line of code for you and run it: install.packages(\"tidyverse\"). You can also just paste and run this instead of using the packages panel.\n\n\nInstall tinytex\nWhen you knit to PDF, R uses a special scientific typesetting program named LaTeX (pronounced “lay-tek” or “lah-tex”; for goofy nerdy reasons, the x is technically the “ch” sound in “Bach”, but most people just say it as “k”—saying “layteks” is frowned on for whatever reason).\nLaTeX is neat and makes pretty documents, but it’s a huge program—the macOS version, for instance, is nearly 4 GB! To make life easier, there’s an R package named tinytex that installs a minimal LaTeX program and that automatically deals with differences between macOS and Windows.\nHere’s how to install tinytex so you can knit to pretty PDFs:\n\nUse the Packages in panel in RStudio to install tinytex like you did above with tidyverse. Alternatively, run install.packages(\"tinytex\") in the console.\nRun tinytex::install_tinytex() in the console.\nWait for a bit while R downloads and installs everything you need.\nThe end! You should now be able to knit to PDF."
  },
  {
    "objectID": "resource/manual_installR/install.html#instalando-r",
    "href": "resource/manual_installR/install.html#instalando-r",
    "title": "Instalación",
    "section": "1. Instalando R",
    "text": "1. Instalando R\n\nAntes de instalar R(v4.2.1), debemos ir al sitio web de CRAN para descargar el programa dando click en “Download R 4.2.1 for Windows”. \n\n\n\n\n\n\n\n\n\n\n\n \n\nUna vez descargado el programa, el primer paso es escoger el idioma del asistente de instalación de R.\n\n\n\n\n\n\n\n\n\n\n\n \n\nEscogido el idioma, para el segundo paso simplemente debemos dar click en “siguiente”.\n\n\n\n\n\n\n\n\n\n\n \n\nEn la siguiente ventana, el tercer paso consiste en elegir en qué carpeta se instalará R y sus dependencias. Si tenemos permisos de administrador en nuestro dispositivo, podemos dejar que R se instale en la carpeta por defecto (“program files”); sin embargo, si esto no es así (por ejemplo si no es nuestro dispositivo o compartimos su uso mediante distintos usuarios), lo más recomendable es elegir otra ubicación, por ejemplo “documentos”. Esto nos evitará problemas de accesos o permisos durante nuestra práctica diaria con R.\n\n\n\n\n\n\n\n\n\n\n\n \n\nA continuación, el cuarto paso consiste simplemente en dar click en “siguiente”.\n\n\n\n\n\n\n\n\n\n\n\n \n\nEn el quinto paso, nos preguntará si deseamos utilizar las opciones de configuración, recomendamos marcar “sí”.\n\n\n\n\n\n\n\n\n\n\n\n \n\nLuego, para el sexto paso seleccionamos MDI y damos click en “siguiente”.\n\n\n\n\n\n\n\n\n\n\n\n \n\nEn el séptimo paso elegimos ayuda HTML y damos click en “siguiente”.\n\n\n\n\n\n\n\n\n\n\n\n \n\nComo octavo paso, en las siguientes dos ventanas daremos click en “siguiente”, lo cual iniciará la instalación de R en nuestro dispositivo y, una vez termine, concluimos dando click en “finalizar”."
  },
  {
    "objectID": "resource/manual_installR/install.html#instalando-rstudio",
    "href": "resource/manual_installR/install.html#instalando-rstudio",
    "title": "Instalación",
    "section": "2. Instalando RStudio",
    "text": "2. Instalando RStudio\n\nAl igual que en la sección anterior, para instalar la versión 2022.07.1+554. de nuestro IDE, primero vamos a la página oficial de Rstudio, escogemos la opción “Free” y damos click en “download RStudio for Windows”.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\nUna vez descargado el programa, iniciamos el asistente de instalación dando click en “Siguiente”.\n\n\n\n\n\n\n\n\n\n\n\n \n\nEn la siguiente ventana nos preguntarán en qué carpeta deseamos instalar nuestro RStudio. Aquí es importante tener las mismas consideraciones que mencionamos en la primera sección: Si no tenemos acceso de administrador, es mejor escoger “Documentos”, de lo contrario, simplemente damos click en “siguiente” en esta ventana e “instalar” en la siguiente.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\nTerminado el proceso de instalación, cerramos el asistente dando click en “Terminar”."
  },
  {
    "objectID": "resource/manual_installR/install.html#instalando-rtools",
    "href": "resource/manual_installR/install.html#instalando-rtools",
    "title": "Instalación",
    "section": "3. Instalando Rtools",
    "text": "3. Instalando Rtools\nSolo se instala Rtools\n\nPor último, vamos a descargar Rtools 4.2 dando click en Rtools42 installer si y solo si tiene sistema operativo Windows. ¡Si tiene sistema operativo Mac o Linux (cualquier distro), no necesita instalar Rtools!\n\n\n\n\n\n\n\n\n\n\n\n \n\nUna vez descargado, iniciamos el asistente de instalación dando click en “next” en las siguientes dos ventanas.\n\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\nA continuación, iniciamos la instalación dando click en “install” y esperamos a que el proceso se complete. Finalmente, cerramos el asistente dando click en “finish”.\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n \n\nSi hemos realizado el proceso correctamente, podremos abrir nuestro RStudio y llegar a esta pantalla:\n\n\n\n\n\n\n\n\n\n\n\n \n\nSi desea más información sobre cómo instalar estos programas en Windows y/o MAC, visite la página oficial del proyecto R."
  },
  {
    "objectID": "resource/manual_installR/install.html#sobre-mac-y-linux",
    "href": "resource/manual_installR/install.html#sobre-mac-y-linux",
    "title": "Instalación",
    "section": "4. Sobre MAC y Linux",
    "text": "4. Sobre MAC y Linux\n\nPara la instalación de R y Rstudio en otros sistemas operativos, como macOS y Linux, vamos a la página oficial de R project y seguimos las mismas indicaciones.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportante\n\n\n\n\n\nEn estos sistemas operativos no es necesario instalar Rtools, solo es necesario para Windows."
  },
  {
    "objectID": "resource/manual_installR/install.html#recursos-adicionales",
    "href": "resource/manual_installR/install.html#recursos-adicionales",
    "title": "Instalación",
    "section": "5. Recursos adicionales",
    "text": "5. Recursos adicionales\nVideos de youtube recomendados:\n\n\n\n\n\n\n\n\n\n\nVideo de henryholder01\n\n \n\n\n\n\n\n\n\n\n\n\nVideo de Renzo Caceres Rossi\n\n \n\n\n\n\n\n\n\n\n\n\nVideo de Roger Miranda\n\n \n\n\n\n\n\n\n\n\n\n\nVideo de R Epidemics Consortium (RECON)\n\n \nManuales disponibles en la web:\n\n\nManual de Alessio Bocco\nManual de Giorgio Boccardo Bosoni y Felipe Ruiz Bruzzone\nManual del libro “Hands-On Programming with R”\nManual de Antoine Soetewey\n\n\n   ___  Este manual fue elaborado por:  Anthony Romero Cerdán (anthony.romeromh@gmail.com)  \n\n\n\n\n\n\n\n\n\n Búscanos en:"
  },
  {
    "objectID": "resource/markdown.html",
    "href": "resource/markdown.html",
    "title": "Using Markdown",
    "section": "",
    "text": "Markdown is a special kind of markup language that lets you format text with simple syntax. You can then use a converter program like pandoc to convert Markdown into whatever format you want: HTML, PDF, Word, PowerPoint, etc. (see the full list of output types here)"
  },
  {
    "objectID": "resource/markdown.html#basic-markdown-formatting",
    "href": "resource/markdown.html#basic-markdown-formatting",
    "title": "Using Markdown",
    "section": "Basic Markdown formatting",
    "text": "Basic Markdown formatting\n\n\n\n\n\n\n\n\n\n\nType…\n\n\n…or…\n\n\n…to get\n\n\n\n\n\n\nSome text in a paragraph.\nMore text in the next paragraph. Always\nuse empty lines between paragraphs.\n\n\n\n\n\nSome text in a paragraph.\n\n\nMore text in the next paragraph. Always use empty lines between paragraphs.\n\n\n\n\n\nItalic\n\n\nItalic\n\n\nItalic\n\n\n\n\nBold\n\n\nBold\n\n\nBold\n\n\n\n\n# Heading 1\n\n\n\n\n\nHeading 1\n\n\n\n\n\n## Heading 2\n\n\n\n\n\nHeading 2\n\n\n\n\n\n### Heading 3\n\n\n\n\n\nHeading 3\n\n\n\n\n\n(Go up to heading level 6 with ######)\n\n\n\n\n\n\n\n\nLink text\n\n\n\n\nLink text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n<code>Inline code with backticks\n\n\n\n\nInline code with backticks\n\n\n\n\n> Blockquote\n\n\n\n\n\n\nBlockquote\n\n\n\n\n\n\n- Things in\n- an unordered\n- list\n\n\n* Things in\n* an unordered\n* list\n\n\n\n\nThings in\n\n\nan unordered\n\n\nlist\n\n\n\n\n\n\n1. Things in\n2. an ordered\n3. list\n\n\n1) Things in\n2) an ordered\n3) list\n\n\n\n\nThings in\n\n\nan ordered\n\n\nlist\n\n\n\n\n\n\nHorizontal line\n\n---\n\n\nHorizontal line\n\n***\n\n\n\nHorizontal line"
  },
  {
    "objectID": "resource/markdown.html#math",
    "href": "resource/markdown.html#math",
    "title": "Using Markdown",
    "section": "Math",
    "text": "Math\n\nBasic math commands\nMarkdown uses LaTeX to create fancy mathematical equations. There are like a billion little options and features available for math equations—you can find helpful examples of the the most common basic commands here. In this class, these will be the most common things you’ll use:\n\n\n\n\n \n  \n    Description \n    Command \n    Output \n  \n \n\n  Letters\n\n    Roman letters \n    a b c d e f \n    \\(a\\ b\\ c\\ d\\ e\\ f\\) \n  \n  \n    Greek letters (see this for all possible letters) \n    \\alpha \\beta \\Gamma \\gamma  \\Delta \\delta \\epsilon \n    \\(\\alpha\\ \\beta\\ \\Gamma\\ \\gamma\\ \\Delta\\ \\delta\\ \\epsilon\\) \n  \n  \n    Letters will automatically be italicized and treated as math variables;if you want actual text in the math, use \\text{} \n    Ew: Treatment = \\beta Good: \\text{Treatment} = \\beta \n    Ew: \\(Treatment = \\beta\\)Good: \\(\\text{Treatment} = \\beta\\) \n  \n  \n    Extra spaces will automatically be removed; if you want a space, use \\  \n    No space: x y  Space: x\\ y \n    No space: \\(x y\\) Space: \\(x \\ y\\) \n  \n  Superscripts and subscripts\n\n    Use ^ to make one character superscripted. \n    x^2 \n    \\(x^2\\) \n  \n  \n    Wrap the superscripted part in {} if there's more than one character \n    x^{2+y} \n    \\(x^{2+y}\\) \n  \n  \n    Use _ to make one character subscripted \n    \\beta_1 \n    \\(\\beta_1\\) \n  \n  \n    Wrap the subscripted part in {} if there's more than one character \n    \\beta_{i, t} \n    \\(\\beta_{i, t}\\) \n  \n  \n    Use superscripts and subscripts simultaneously \n    \\beta_1^{\\text{Treatment}} \n    \\(\\beta_1^{\\text{Treatment}}\\) \n  \n  \n    You can even nest them \n    x^{2^{2^2}} \n    \\(x^{2^{2^2}}\\) \n  \n  Math operations\n\n    Addition \n    2 + 5 = 7 \n    \\(2 + 5 = 7\\) \n  \n  \n    Subtraction \n    2 - 5 = -3 \n    \\(2 + 5 = -3\\) \n  \n  \n    Multiplication \n    x \\times y  x \\cdot y \n    \\(x \\times y\\)  \\(x \\cdot y\\) \n  \n  \n    Division \n    8 \\div 2 \n    \\(8 \\div 2\\) \n  \n  \n    Fractions \n    \\frac{8}{2} \n    \\(\\frac{8}{2}\\) \n  \n  \n    Square roots; use [3] for other roots \n    \\sqrt{81} = 9  \\sqrt[3]{27} = 3 \n    \\(\\sqrt{81} = 9\\)  \\(\\sqrt[3]{27} = 3\\) \n  \n  \n    Summation; use sub/superscripts for extra details \n    \\sum x  \\sum_{n=1}^{\\infty} \\frac{1}{n} \n    \\(\\sum x\\)  \\(\\sum_{n=1}^{\\infty} \\frac{1}{n}\\) \n  \n  \n    Products; use sub/superscripts for extra details \n    \\prod x  \\prod_{n=1}^{5} n^2 \n    \\(\\prod x\\)  \\(\\prod_{n=1}^{5} n^2\\) \n  \n  \n    Integrals; use sub/superscripts for extra details \n    \\int x^2 \\ dx  \\int_{1}^{100} x^2 \\ dx \n    \\(\\int x^2 \\ dx\\)  \\(\\int_{1}^{100} x^2 \\ dx\\) \n  \n  Extra symbols\n\n    Add a bar for things like averages \n    \\bar{x} \n    \\(\\bar{x}\\) \n  \n  \n    Use an overline for longer things \n    Ew: \\bar{abcdef}  Good: \\overline{abcdef} \n    Ew: \\(\\bar{abcdef}\\)  Good: \\(\\overline{abcdef}\\) \n  \n  \n    Add a hat for things like estimates \n    \\hat{y} \n    \\(\\hat{y}\\) \n  \n  \n    Use a wide hat for longer things \n    Ew: \\hat{abcdef}  Good: \\widehat{abcdef} \n    Ew: \\(\\hat{abcdef}\\)  Good: \\(\\widehat{abcdef}\\) \n  \n  \n    Use arrows for DAG-like things \n    Z \\rightarrow Y \\leftarrow X \n    \\(Z \\rightarrow Y \\leftarrow X\\) \n  \n  Bonus fun\n\n    Use colors!; see here for more details and here for a list of color names \n    \\color{red}{y} = \\color{blue}{\\beta_1 x_1} \n    \\(\\color{red}{y}\\ \\color{black}{=}\\ \\color{blue}{\\beta_1 x_1}\\) \n  \n\n\n\n\n\n\n\nUsing math inline\nYou can use math in two different ways: inline or in a display block. To use math inline, wrap it in single dollar signs, like $y = mx + b$:\n\n\n\n\n\n\n\n\n\nType…\n\n\n…to get\n\n\n\n\n\n\nBased on the DAG, the regression model for\nestimating the effect of education on wages\nis $\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon$, \nor $\\text{Wages} = \\beta_0 + \n\\beta_1 \\text{Education} + \\epsilon$.\n\n\nBased on the DAG, the regression model for estimating the effect of education on wages is \\(\\hat{y} = \\beta_0 + \\beta_1 x_1 + \\epsilon\\), or \\(\\text{Wages} = \\beta_0 + \\beta_1 \\text{Education} + \\epsilon\\).\n\n\n\n\n\n\n\nUsing math in a block\nTo put an equation on its own line in a display block, wrap it in double dollar signs, like this:\nType…\nThe quadratic equation was a way to solve for $x$ in high school math:\n\n$$\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n$$\n\n\n…to get…\n\nThe quadratic equation was a way to solve for \\(x\\) in high school math:\n\\[\nx = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}\n\\]\n\n\n\n\nDollar signs and math\nBecause dollar signs are used to indicate math equations, you can’t just use dollar signs like normal if you’re writing about actual dollars. For instance, if you write This book costs $5.75 and this other costs $40, Markdown will treat everything that comes between the dollar signs as math, like so: “This book costs \\($5.75 and this other costs $40\\)”.\nTo get around that, put a backslash (\\) in front of the dollar signs, so that This book costs \\$5.75 and this other costs \\$40 becomes “This book costs $5.75 and this other costs $40”."
  },
  {
    "objectID": "resource/markdown.html#tables",
    "href": "resource/markdown.html#tables",
    "title": "Using Markdown",
    "section": "Tables",
    "text": "Tables\nThere are 4 different ways to hand-create tables in Markdown—I say “hand-create” because it’s normally way easier to use R to generate these things with packages like kableExtra (use kable()) or pander (use pandoc.table()). The two most common are simple tables and pipe tables. You should look at the full documentation here.\nFor simple tables, type…\n  Right     Left     Center     Default\n-------     ------ ----------   -------\n     12     12        12            12\n    123     123       123          123\n      1     1          1             1\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nCenter\nDefault\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1\n\n\n\nFor pipe tables, type…\n| Right | Left | Default | Center |\n|------:|:-----|---------|:------:|\n|   12  |  12  |    12   |    12  |\n|  123  |  123 |   123   |   123  |\n|    1  |    1 |     1   |     1  |\n\nTable: Caption goes here\n…to get…\n\nCaption goes here\n\n\nRight\nLeft\nDefault\nCenter\n\n\n\n\n12\n12\n12\n12\n\n\n123\n123\n123\n123\n\n\n1\n1\n1\n1"
  },
  {
    "objectID": "resource/markdown.html#footnotes",
    "href": "resource/markdown.html#footnotes",
    "title": "Using Markdown",
    "section": "Footnotes",
    "text": "Footnotes\nThere are two different ways to add footnotes (see here for complete documentation): regular and inline.\nRegular notes need (1) an identifier and (2) the actual note. The identifier can be whatever you want. Some people like to use numbers like [^1], but if you ever rearrange paragraphs or add notes before #1, the numbering will be wrong (in your Markdown file, not in the output; everything will be correct in the output). Because of that, I prefer to use some sort of text label:\nType…\nHere is a footnote reference[^1] and here is another [^note-on-dags].\n\n[^1]: This is a note.\n\n[^note-on-dags]: DAGs are neat. \n\nAnd here's more of the document.\n…to get…\n\nHere is a footnote reference1 and here is another.2\nAnd here’s more of the document.\n\n\n\n\n\nThis is a note.↩︎\n\n\n\n\nDAGs are neat.↩︎\n\n\n\n\n\n\nYou can also use inline footnotes with ^[Text of the note goes here], which are often easier because you don’t need to worry about identifiers:\nType…\nCausal inference is neat.^[But it can be hard too!]\n…to get…\n\nCausal inference is neat.1\n\n\n\n\n\nBut it can be hard too!↩︎"
  },
  {
    "objectID": "resource/markdown.html#front-matter",
    "href": "resource/markdown.html#front-matter",
    "title": "Using Markdown",
    "section": "Front matter",
    "text": "Front matter\nYou can include a special section at the top of a Markdown document that contains metadata (or data about your document) like the title, date, author, etc. This section uses a special simple syntax named YAML (or “YAML Ain’t Markup Language”) that follows this basic outline: setting: value for setting. Here’s an example YAML metadata section. Note that it must start and end with three dashes (---).\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\n---\nYou can put the values inside quotes (like the date and name in the example above), or you can leave them outside of quotes (like the title in the example above). I typically use quotes just to be safe—if the value you’re using has a colon (:) in it, it’ll confuse Markdown since it’ll be something like title: My cool title: a subtitle, which has two colons. It’s better to do this:\n---\ntitle: \"My cool title: a subtitle\"\n---\nIf you want to use quotes inside one of the values (e.g. your document is An evaluation of \"scare quotes\"), you can use single quotes instead:\n---\ntitle: 'An evaluation of \"scare quotes\"'\n---"
  },
  {
    "objectID": "resource/markdown.html#citations",
    "href": "resource/markdown.html#citations",
    "title": "Using Markdown",
    "section": "Citations",
    "text": "Citations\nOne of the most powerful features of Markdown + pandoc is the ability to automatically cite things and generate bibliographies. to use citations, you need to create a BibTeX file (ends in .bib) that contains a database of the things you want to cite. You can do this with bibliography managers designed to work with BibTeX directly (like BibDesk on macOS), or you can use Zotero (macOS and Windows) to export a .bib file. You can download an example .bib file of all the readings from this class here.\nComplete details for using citations can be found here. In brief, you need to do three things:\n\nAdd a bibliography: entry to the YAML metadata:\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\n---\nChoose a citation style based on a CSL file. The default is Chicago author-date, but you can choose from 2,000+ at this repository. Download the CSL file, put it in your project folder, and add an entry to the YAML metadata (or provide a URL to the online version):\n---\ntitle: Title of your document\ndate: \"January 13, 2020\"\nauthor: \"Your name\"\nbibliography: name_of_file.bib\ncsl: \"https://raw.githubusercontent.com/citation-style-language/styles/master/apa.csl\"\n---\nSome of the most common CSLs are:\n\nChicago author-date\nChicago note-bibliography\nChicago full note-bibliography (no shortened notes or ibids)\nAPA 7th edition\nMLA 8th edition\n\nCite things in your document. Check the documentation for full details of how to do this. Essentially, you use @citationkey inside square brackets ([]):\n\n\n\n\n\n\n\n\nType…\n…to get…\n\n\n\n\nCausal inference is neat [@Rohrer:2018;\n@AngristPischke:2015].\nCausal inference is neat (Rohrer 2018; Angrist y Pischke 2015).\n\n\nCausal inference is neat [see @Rohrer:2018,\np. 34; also @AngristPischke:2015, chapter 1]\nCausal inference is neat (see Rohrer 2018, 34; also Angrist y Pischke 2015, chapter 1)\n\n\nAngrist and Pischke say causal inference\nis neat [-@AngristPischke:2015; see also\n@Rohrer:2018].\nAngrist and Pischke say causal inference is neat (2015; see also Rohrer 2018).\n\n\n@AngristPischke:2015 [chapter 1] say causal\ninference is neat, and @Rohrer:2018 agrees.\nAngrist y Pischke (2015, chapter 1) say causal inference is neat, and Rohrer (2018) agrees.\n\n\n\nAfter compiling, you should have a perfectly formatted bibliography added to the end of your document too:\n\nAngrist, Joshua D., and Jörn-Steffen Pischke. 2015. Mastering ’Metrics: The Path from Cause to Effect. Princeton, NJ: Princeton University Press.\nRohrer, Julia M. 2018. “Thinking Clearly About Correlations and Causation: Graphical Causal Models for Observational Data.” Advances in Methods and Practices in Psychological Science 1 (1): 27–42. https://doi.org/10.1177/2515245917745629."
  },
  {
    "objectID": "resource/markdown.html#other-references",
    "href": "resource/markdown.html#other-references",
    "title": "Using Markdown",
    "section": "Other references",
    "text": "Other references\nThese websites have additional details and examples and practice tools:\n\nCommonMark’s Markdown tutorial: A quick interactive Markdown tutorial.\nMarkdown tutorial: Another interactive tutorial to practice using Markdown.\nMarkdown cheatsheet: Useful one-page reminder of Markdown syntax.\nThe Plain Person’s Guide to Plain Text Social Science: A comprehensive explanation and tutorial about why you should write data-based reports in Markdown."
  },
  {
    "objectID": "resource/r.html",
    "href": "resource/r.html",
    "title": "R",
    "section": "",
    "text": "I highly recommend subscribing to the R Weekly newsletter. This e-mail is sent every Monday and is full of helpful tutorials about how to do stuff with R.\nSearching for help with R on Google can sometimes be tricky because the program name is a single letter. Google is generally smart enough to figure out what you mean when you search for “r scatterplot”, but if it does struggle, try searching for “rstats” instead (e.g. “rstats scatterplot”).\nIf you use Twitter, post R-related questions and content with #rstats. The community there is exceptionally generous and helpful. Also check out StackOverflow (a Q&A site with hundreds of thousands of answers to all sorts of programming questions) and RStudio Community (a forum specifically designed for people using RStudio and the tidyverse (i.e. you)).\nThese resources are also really really helpful:\n\nR for Data Science: A free online book for learning the basics of R and the tidyverse.\nR and RStudio cheat sheets: A large collection of simple cheat sheets for RStudio, ggplot2, and other R-related things.\nStat 545: Dr. Jenny Bryan at RStudio has an entire introductory course in R, visualization, and data analysis online.\nSTA 112FS: Data Science: Dr. Mine Çetinkaya-Rundel at the University of Edinburgh / Duke University has an entire introductory course in R, visualization, and data science online.\nCSE 631: Principles & Practice of Data Visualization: Yet another introductory course for R and ggplot2 by Dr. Alison Presmanes Hill at RStudio."
  },
  {
    "objectID": "resource/r.html#r-in-the-wild",
    "href": "resource/r.html#r-in-the-wild",
    "title": "R",
    "section": "R in the wild",
    "text": "R in the wild\nA popular (and increasingly standard) way for sharing your analyses and visualizations is to post an annotated explanation of your process somewhere online. RStudio allows you to publish knitted HTML files directly to RPubs, but you can also post your output to a blog or other type of website.1 Reading these kinds of posts is one of the best ways to learn R, since they walk you through each step of the process and show the code and output.\nHere are some of the best examples I’ve come across:\n\nText analysis of Trump’s tweets confirms he writes only the (angrier) Android half (with a follow-up)\nBob Ross - Joy of Painting\nBechdel analysis using the tidyverse: There are also a bunch of other examples using data from FiveThirtyEight.\nSexism on the Silver Screen: Exploring film’s gender divide\nComparison of Quentin Tarantino Movies by Box Office and the Bechdel Test\nWho came to vote in Utah’s caucuses?\nHealth care indicators in Utah counties\nSong lyrics across the United States\nA decade (ish) of listening to Sigur Rós\nWhen is Tom peeping these days?: There are a also bunch of final projects from other R and data visualization classes here and here.\nMapping Fall Foliage\nGeneral (Attys) Distributions\nDisproving Approval"
  },
  {
    "objectID": "resource/rmarkdown.html",
    "href": "resource/rmarkdown.html",
    "title": "Using R Markdown",
    "section": "",
    "text": "R Markdown is regular Markdown with R code and output sprinkled in. You can do everything you can with regular Markdown, but you can incorporate graphs, tables, and other R output directly in your document. You can create HTML, PDF, and Word documents, PowerPoint and HTML presentations, websites, books, and even interactive dashboards with R Markdown. This whole course website is created with R Markdown (and a package named blogdown).\nThe documentation for R Markdown is extremely comprehensive, and their tutorials and cheatsheets are excellent—rely on those.\nHere are the most important things you’ll need to know about R Markdown in this class:"
  },
  {
    "objectID": "resource/rmarkdown.html#key-terms",
    "href": "resource/rmarkdown.html#key-terms",
    "title": "Using R Markdown",
    "section": "Key terms",
    "text": "Key terms\n\nDocument: A Markdown file where you type stuff\nChunk: A piece of R code that is included in your document. It looks like this:\n\n```{r}\n# Code goes here\n```\n\nThere must be an empty line before and after the chunk. The final three backticks must be the only thing on the line—if you add more text, or if you forget to add the backticks, or accidentally delete the backticks, your document will not knit correctly.\nKnit: When you “knit” a document, R runs each of the chunks sequentially and converts the output of each chunk into Markdown. R then runs the knitted document through pandoc to convert it to HTML or PDF or Word (or whatever output you’ve selected).\nYou can knit by clicking on the “Knit” button at the top of the editor window, or by pressing ⌘⇧K on macOS or control + shift + K on Windows."
  },
  {
    "objectID": "resource/rmarkdown.html#add-chunks",
    "href": "resource/rmarkdown.html#add-chunks",
    "title": "Using R Markdown",
    "section": "Add chunks",
    "text": "Add chunks\nThere are three ways to insert chunks:\n\nPress ⌘⌥I on macOS or control + alt + I on Windows\nClick on the “Insert” button at the top of the editor window\n\n\n\n\n\n\n\n\n\n\n\nManually type all the backticks and curly braces (don’t do this)"
  },
  {
    "objectID": "resource/rmarkdown.html#chunk-names",
    "href": "resource/rmarkdown.html#chunk-names",
    "title": "Using R Markdown",
    "section": "Chunk names",
    "text": "Chunk names\nYou can add names to chunks to make it easier to navigate your document. If you click on the little dropdown menu at the bottom of your editor in RStudio, you can see a table of contents that shows all the headings and chunks. If you name chunks, they’ll appear in the list. If you don’t include a name, the chunk will still show up, but you won’t know what it does.\n\n\n\n\n\n\n\n\n\nTo add a name, include it immediately after the {r in the first line of the chunk. Names cannot contain spaces, but they can contain underscores and dashes. All chunk names in your document must be unique.\n```{r name-of-this-chunk}\n# Code goes here\n```"
  },
  {
    "objectID": "resource/rmarkdown.html#chunk-options",
    "href": "resource/rmarkdown.html#chunk-options",
    "title": "Using R Markdown",
    "section": "Chunk options",
    "text": "Chunk options\nThere are a bunch of different options you can set for each chunk. You can see a complete list in the RMarkdown Reference Guide or at knitr’s website.\nOptions go inside the {r} section of the chunk:\n```{r name-of-this-chunk, warning=FALSE, message=FALSE}\n# Code goes here\n```\nThe most common chunk options are these:\n\nfig.width=5 and fig.height=3 (or whatever number you want): Set the dimensions for figures\necho=FALSE: The code is not shown in the final document, but the results are\nmessage=FALSE: Any messages that R generates (like all the notes that appear after you load a package) are omitted\nwarning=FALSE: Any warnings that R generates are omitted\ninclude=FALSE: The chunk still runs, but the code and results are not included in the final document\n\nYou can also set chunk options by clicking on the little gear icon in the top right corner of any chunk:"
  },
  {
    "objectID": "resource/rmarkdown.html#inline-chunks",
    "href": "resource/rmarkdown.html#inline-chunks",
    "title": "Using R Markdown",
    "section": "Inline chunks",
    "text": "Inline chunks\nYou can also include R output directly in your text, which is really helpful if you want to report numbers from your analysis. To do this, use `r r_code_here`.\nIt’s generally easiest to calculate numbers in a regular chunk beforehand and then use an inline chunk to display the value in your text. For instance, this document…\n```{r find-avg-mpg, echo=FALSE}\navg_mpg <- mean(mtcars$mpg)\n```\n\nThe average fuel efficiency for cars from 1974 was `r round(avg_mpg, 1)` miles per gallon.\n… would knit into this:\n\nThe average fuel efficiency for cars from 1974 was 20.1 miles per gallon."
  },
  {
    "objectID": "resource/rmarkdown.html#output-formats",
    "href": "resource/rmarkdown.html#output-formats",
    "title": "Using R Markdown",
    "section": "Output formats",
    "text": "Output formats\nYou can specify what kind of document you create when you knit in the YAML front matter.\ntitle: \"My document\"\noutput:\n  html_document: default\n  pdf_document: default\n  word_document: default\nYou can also click on the down arrow on the “Knit” button to choose the output and generate the appropriate YAML. If you click on the gear icon next to the “Knit” button and choose “Output options”, you change settings for each specific output type, like default figure dimensions or whether or not a table of contents is included.\n\n\n\n\n\n\n\n\n\nThe first output type listed under output: will be what is generated when you click on the “Knit” button or press the keyboard shortcut (⌘⇧K on macOS; control + shift + K on Windows). If you choose a different output with the “Knit” button menu, that output will be moved to the top of the output section.\nThe indentation of the YAML section matters, especially when you have settings nested under each output type. Here’s what a typical output section might look like:\n---\ntitle: \"My document\"\nauthor: \"My name\"\ndate: \"January 13, 2020\"\noutput: \n  html_document: \n    toc: yes\n    fig_caption: yes\n    fig_height: 8\n    fig_width: 10\n  pdf_document: \n    latex_engine: xelatex  # More modern PDF typesetting engine\n    toc: yes\n  word_document: \n    toc: yes\n    fig_caption: yes\n    fig_height: 4\n    fig_width: 5\n---"
  },
  {
    "objectID": "resource/style.html",
    "href": "resource/style.html",
    "title": "R style suggestions",
    "section": "",
    "text": "R is fairly forgiving about how you type code (unlike other languages like Python, where miscounting spaces can ruin your code!). All of these things will do exactly the same thing:\n\nmpg %>% \n  filter(cty > 10, class == \"compact\")\n\nmpg %>% filter(cty > 10, class == \"compact\")\n\nmpg %>% \n  filter(cty > 10, \n         class == \"compact\")\n\nmpg %>% filter(cty>10, class==\"compact\")\n\nfilter(mpg,cty>10,class==\"compact\")\n\nmpg %>% \nfilter(cty > 10, \n                        class == \"compact\")\n\nfilter ( mpg,cty>10,     class==\"compact\" )\n\nBut you’ll notice that only a few of those iterations (the first three) are easily readable.\nTo help improve readability and make it easier to share code with others, there’s an unofficial style guide for writing R code. It’s fairly short and just has lots of examples of good and bad ways of writing code (naming variables, dealing with long lines, using proper indentation levels, etc.)—you should glance through it some time.\nRStudio has a built-in way of cleaning up your code. Select some code, press ctrl + i (on Windows) or ⌘ + i (on macOS), and R will reformat the code for you. It’s not always perfect, but it’s really helpful for getting indentation right without having to manually hit space a billion times."
  },
  {
    "objectID": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "href": "resource/style.html#main-style-things-to-pay-attention-to-for-this-class",
    "title": "R style suggestions",
    "section": "Main style things to pay attention to for this class",
    "text": "Main style things to pay attention to for this class\n\nImportant note: I won’t ever grade you on any of this! If you submit something like filter(mpg,cty>10,class==\"compact\"), I might recommend adding spaces, but it won’t affect your grade or points or anything.\n\n\nSpacing\n\nSee the “Spacing” section in the tidyverse style guide.\n\nPut spaces after commas (like in regular English):\n\n# Good\nfilter(mpg, cty > 10)\n\n# Bad\nfilter(mpg , cty > 10)\nfilter(mpg ,cty > 10)\nfilter(mpg,cty > 10)\n\nPut spaces around operators like +, -, >, =, etc.:\n\n# Good\nfilter(mpg, cty > 10)\n\n# Bad\nfilter(mpg, cty>10)\nfilter(mpg, cty> 10)\nfilter(mpg, cty >10)\n\nDon’t put spaces around parentheses that are parts of functions:\n\n# Good\nfilter(mpg, cty > 10)\n\n# Bad\nfilter (mpg, cty > 10)\nfilter ( mpg, cty > 10)\nfilter( mpg, cty > 10 )\n\n\n\nLong lines\n\nSee the “Long lines” section in the tidyverse style guide.\n\nIt’s generally good practice to not have really long lines of code. A good suggestion is to keep lines at a maximum of 80 characters. Instead of counting characters by hand (ew), in RStudio go to “Tools” > “Global Options” > “Code” > “Display” and check the box for “Show margin”. You should now see a really thin line indicating 80 characters. Again, you can go beyond this—that’s fine. It’s just good practice to avoid going too far past it.\nYou can add line breaks inside longer lines of code. Line breaks should come after commas, and things like function arguments should align within the function:\n\n# Good\nfilter(mpg, cty > 10, class == \"compact\")\n\n# Good\nfilter(mpg, cty > 10, \n       class == \"compact\")\n\n# Good\nfilter(mpg,\n       cty > 10,\n       class == \"compact\")\n\n# Bad\nfilter(mpg, cty > 10, class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \"suv\", \"2seater\", \"minivan\"))\n\n# Good\nfilter(mpg, \n       cty > 10, \n       class %in% c(\"compact\", \"pickup\", \"midsize\", \"subcompact\", \n                    \"suv\", \"2seater\", \"minivan\"))\n\n\n\nPipes (%>%) and ggplot layers (+)\nPut each layer of a ggplot plot on separate lines, with the + at the end of the line, indented with two spaces:\n\n# Good\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() +\n  geom_smooth() +\n  theme_bw()\n\n# Bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) +\n  geom_point() + geom_smooth() +\n  theme_bw()\n\n# Super bad\nggplot(mpg, aes(x = cty, y = hwy, color = class)) + geom_point() + geom_smooth() + theme_bw()\n\n# Super bad and won't even work\nggplot(mpg, aes(x = cty, y = hwy, color = class))\n  + geom_point()\n  + geom_smooth() \n  + theme_bw()\n\nPut each step in a dplyr pipeline on separate lines, with the %>% at the end of the line, indented with two spaces:\n\n# Good\nmpg %>% \n  filter(cty > 10) %>% \n  group_by(class) %>% \n  summarize(avg_hwy = mean(hwy))\n\n# Bad\nmpg %>% filter(cty > 10) %>% group_by(class) %>% \n  summarize(avg_hwy = mean(hwy))\n\n# Super bad\nmpg %>% filter(cty > 10) %>% group_by(class) %>% summarize(avg_hwy = mean(hwy))\n\n# Super bad and won't even work\nmpg %>% \n  filter(cty > 10)\n  %>% group_by(class)\n  %>% summarize(avg_hwy = mean(hwy))\n\n\n\nComments\n\nSee the “Comments” section in the tidyverse style guide.\n\nComments should start with a comment symbol and a single space: #\n\n# Good\n\n#Bad\n\n    #Bad\n\nIf the comment is really short (and won’t cause you to go over 80 characters in the line), you can include it in the same line as the code, separated by at least two spaces (it works with one space, but using a couple can enhance readability):\n\nmpg %>% \n  filter(cty > 10) %>%  # Only rows where cty is 10 +\n  group_by(class) %>%  # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nYou can add extra spaces to get inline comments to align, if you want:\n\nmpg %>% \n  filter(cty > 10) %>%            # Only rows where cty is 10 +\n  group_by(class) %>%             # Divide into class groups\n  summarize(avg_hwy = mean(hwy))  # Find the average hwy in each group\n\nIf the comment is really long, you can break it into multiple lines. RStudio can do this for you if you go to “Code” > “Reflow comment”\n\n# Good\n# Happy families are all alike; every unhappy family is unhappy in its own way.\n# Everything was in confusion in the Oblonskys’ house. The wife had discovered\n# that the husband was carrying on an intrigue with a French girl, who had been\n# a governess in their family, and she had announced to her husband that she\n# could not go on living in the same house with him. This position of affairs\n# had now lasted three days, and not only the husband and wife themselves, but\n# all the members of their family and household, were painfully conscious of it.\n\n# Bad\n# Happy families are all alike; every unhappy family is unhappy in its own way. Everything was in confusion in the Oblonskys’ house. The wife had discovered that the husband was carrying on an intrigue with a French girl, who had been a governess in their family, and she had announced to her husband that she could not go on living in the same house with him. This position of affairs had now lasted three days, and not only the husband and wife themselves, but all the members of their family and household, were painfully conscious of it.\n\nThough, if you’re dealing with comments that are that long, consider putting the text in R Markdown instead and having it be actual prose."
  },
  {
    "objectID": "resource/unzipping.html",
    "href": "resource/unzipping.html",
    "title": "Unzipping files",
    "section": "",
    "text": "Because RStudio projects typically consist of multiple files (R scripts, datasets, graphical output, etc.) the easiest way to distribute them to you for examples, assignments, and projects is to combine all the different files in to a single compressed collection called a zip file. When you unzip a zipped file, your operating system extracts all the files that are contained inside into a new folder on your computer.\nUnzipping files on macOS is trivial, but unzipping files on Windows can mess you up if you don’t pay careful attention. Here’s a helpful guide to unzipping files on both macOS and Windows."
  },
  {
    "objectID": "resource/unzipping.html#unzipping-files-on-macos",
    "href": "resource/unzipping.html#unzipping-files-on-macos",
    "title": "Unzipping files",
    "section": "Unzipping files on macOS",
    "text": "Unzipping files on macOS\nDouble click on the downloaded .zip file. macOS will automatically create a new folder with the same name as the .zip file, and all the file’s contents will be inside. Double click on the RStudio Project file (.Rproj) to get started."
  },
  {
    "objectID": "resource/unzipping.html#unzipping-files-on-windows",
    "href": "resource/unzipping.html#unzipping-files-on-windows",
    "title": "Unzipping files",
    "section": "Unzipping files on Windows",
    "text": "Unzipping files on Windows\ntl;dr: Right click on the .zip file, select “Extract All…”, and work with the resulting unzipped folder.\nUnlike macOS, Windows does not automatically unzip things for you. If you double click on the .zip file, Windows will show you what’s inside, but it will do so without actually extracting anything. This can be is incredibly confusing! Here’s what it looks like—the only clues that this folder is really a .zip file are that there’s a “Compressed Folder Tools” tab at the top, and there’s a “Ratio” column that shows how much each file is compressed.\n\n\n\n\n\nIt is very tempting to try to open files from this view. However, if you do, things will break and you won’t be able to correctly work with any of the files in the zipped folder. If you open the R Project file, for instance, RStudio will point to a bizarre working directory buried deep in some temporary folder:\n\n\n\n\n\nYou most likely won’t be able to open any data files or save anything, which will be frustrating.\nInstead, you need to right click on the .zip file and select “Extract All…”:\n\n\n\n\n\nThen choose where you want to unzip all the files and click on “Extract”\n\n\n\n\n\nYou should then finally have a real folder with all the contents of the zipped file. Open the R Project file and RStudio will point to the correct working directory and everything will work."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Cronograma",
    "section": "",
    "text": "¡Aquí encontrará la hora de ruta para el curso!\n\nContenido (): Esta página contiene las clases, diapositivas y conferencias grabadas de la semana. Lea y mire estos antes de nuestra reunión sincrónica.\nEjemplos (): Esta página contiene código R completamente anotado e información complementaria que puede usar como referencia para sus tareas. Esta es solo una página referencial, no necesariamente tiene que hacer nada aquí. Algunas secciones también contienen videos de código con ejemplos para que pueda ver cómo se ve trabajar con R en tiempo real. Esta página será muy útil mientras trabaja en sus tareas.\nTarea (): Esta página contiene las instrucciones para cada tarea. Los informes semanales deben entregarse antes del 11:59 p. m. del día domingo de la siguiente semana. Existe una semana adicional para entrega retrasada de las tareas encomendadas.\n\n\n\n\n\n\n\n\n\n\nTítulo\n\n\nContenido\n\n\nEjemplo\n\n\nTarea\n\n\n\n\n\n\nSesión 1\n\n\n\n\n6/08/2022 \n\n\nIntroducción a R y Rstudio\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 2\n\n\n\n\n6/08/2022 \n\n\nAnálisis descriptivo univariado\n\n\n\n\n\n\n\n\n\n\n\n\n\n6/08/2022 –14/08/2022\n\n\nProblem set 1  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 3\n\n\n\n\n13/08/2022\n\n\nAnálisis descriptivo bivariado\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 4\n\n\n\n\n13/08/2022\n\n\nReporte descriptivo reproducible\n\n\n\n\n\n\n\n\n\n\n\n\n\n13/08/2022–21/08/2022\n\n\nProblem set 2  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTítulo\n\n\nContenido\n\n\nEjemplo\n\n\nTarea\n\n\n\n\n\n\nSesión 5\n\n\n\n\n20/08/2022\n\n\nPrincipios de inferencia estadística\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 6\n\n\n\n\n20/08/2022\n\n\nEstimación bajo inferencia clásica\n\n\n\n\n\n\n\n\n\n\n\n\n\n20/08/2022–28/08/2022\n\n\nProblem set 3  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 7\n\n\n\n\n27/08/2022\n\n\nEstimación bajo inferencia por remuestreo\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 8\n\n\n\n\n27/08/2022\n\n\nPruebas de hipótesis: Paradigma clásico y bajo remuestreo\n\n\n\n\n\n\n\n\n\n\n\n\n\n27/08/2022–4/09/2022 \n\n\nProblem set 4  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTítulo\n\n\nContenido\n\n\nEjemplo\n\n\nTarea\n\n\n\n\n\n\nSesión 9\n\n\n\n\n3/09/2022 \n\n\nPruebas de hipótesis para 1 y 2 grupos\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 10\n\n\n\n\n3/09/2022 \n\n\nPruebas de hipótesis para 3 o más grupos\n\n\n\n\n\n\n\n\n\n\n\n\n\n3/09/2022 –11/09/2022\n\n\nProblem set 5  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 11\n\n\n\n\n10/09/2022\n\n\nPruebas de hipótesis para proporciones\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTítulo\n\n\nContenido\n\n\nEjemplo\n\n\nTarea\n\n\n\n\n\n\nSesión 12\n\n\n\n\n10/09/2022\n\n\nIntervalos de confianza: buenas prácticas y errores de concepto\n\n\n\n\n\n\n\n\n\n\n\n\n\n10/09/2022–18/09/2022\n\n\nProblem set 6  (enviar antes de 11:59 p. m.)\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 13\n\n\n\n\n17/09/2022\n\n\nValor p: buenas prácticas y errores de concepto\n\n\n\n\n\n\n\n\n\n\n\n\n\nSesión 14\n\n\n\n\n17/09/2022\n\n\nReporte reproducible de inferencia estadística\n\n\n\n\n\n\n\n\n\n\n\n\n\n17/09/2022–25/09/2022\n\n\nProblem set 7"
  },
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Percy Soto-Becerra, M.D., M.Sc(c)\n   Virtual: Vimeo & Google Meet\n   percys1991@gmail.com\n   psotob91\n   Schedule an appointment\n\n\n\n\n\n   Sábados\n   06 de agosto a 25 de setiembre, 2022\n   Asincrónico: Sábados 3 pm   Sincrónico: Martes o Jueves\n   Asincrónico: Vimeo   Sincrónico: Google Meet\n   Discord"
  },
  {
    "objectID": "syllabus.html#objetivos-del-curso",
    "href": "syllabus.html#objetivos-del-curso",
    "title": "Syllabus",
    "section": "Objetivos del curso",
    "text": "Objetivos del curso\nAl finalizar este curso, el participante tendrá la capacidad de escribir código R con estilo tidyverse, mediante flujos de trabajo reproducibles, para el análisis descriptivo de variables numéricas y categóricas, reporte automatizado y reproducible de resultados, estimación e interpretación de intervalos de confianza y pruebas de hipótesis, e interpretación del valor p."
  },
  {
    "objectID": "syllabus.html#presentación-del-curso",
    "href": "syllabus.html#presentación-del-curso",
    "title": "Syllabus",
    "section": "Presentación del curso",
    "text": "Presentación del curso\nEste tercer módulo de la serie R para Ciencia de Datos en Salud*, organizado por Inkastats Data Science Solutions | Medical Branch, busca desarrollar, en el participante, competencias en el análisis y reporte descriptivo de los datos, de tal forma que pueda transmitir información relevante en publicaciones científicas, reportes, informes técnicos o estrategias de comunicación en salud.\nAsimismo, brindaremos los fundamentos sobre inferencia estadística desde dos perspectivas, la clásica y la basada en remuestreo (bootstrapping y pruebas de permutación), de tal forma que el alumno cuente con todas las herramientas más comúnmente utilizadas a la hora de realizar inferencia estadística. En particular, los métodos no paramétricos clásicos y el remuestreo permiten realizar inferencias robustas incluso cuando los datos no cumplen los supuestos clásicos o cuando no existe método parámetrico para computarlos.\nEl curso también abordará los errores más comunes en la interpretación del valor p y el intervalo de confianza, así como pautas para reportar apropiadamente estos resultados en artículos científicos de acuerdo con el estado de arte actual. En la última década, se han conformado iniciativas internacionales para ayudar a usuarios de la estadística a mejorar la calidad metodológica y de reporte de los métodos bioestadísticos. Este curso presentará las principales guías de reporte vigentes para que los alumnos sean capaces de ponerlas en práctica en su quehacer diario."
  },
  {
    "objectID": "syllabus.html#por-qué-r-y-rstudio",
    "href": "syllabus.html#por-qué-r-y-rstudio",
    "title": "Syllabus",
    "section": "¿Por qué R y RStudio?",
    "text": "¿Por qué R y RStudio?\nEl software R es un lenguaje de programación de acceso libre e ideal como entorno para el análisis estadístico y gráfico, reporte, presentación de datos, etc., lo que lo convierte en una de las opciones líderes a nivel mundial para la Ciencia de Datos en Salud. En la última década ha ocurrido una revolución en la computación estadística. Lenguajes de código abierto como R y Python han superado a programas propietarios más antiguos y costosos como SAS, Stata y SPSS. Asimismo, la literatura (libros, blogs, foros de ayuda, etc.) acerca de R es extensa en comparación con la de otros programas, por lo que resulta más fácil encontrar soluciones a problemas (relativamente complejos) con los que los usuarios a menudo se enfrentan.\nAsimismo, R tiene varios dialectos, todos los cuales tienen fortalezas y debilidades. Ciertamente, ser fluido en R implica manejar más de un dialecto si no todos. Sin embargo, el dialecto de tiyverse es probablemente uno de los más consistentes, completos y en constante desarrollo y mantención, por lo que es uno de los más rentables de aprender cuando se trata de R. Este curso abordará principalmente el estilo R tidy, aunque también hará uso del dialecto de R base y otros dialectos cuando sea propicio.\nPor otro lado, R Studio es una interfaz que permite una mejor comunicación eentre el usuario y R. Piense en R como el motor de un automóvil y en R Studio como el tablero de mando del automóvil: R hace el trabajo duro al calcular y aplicar los métodos estadísticos, mientras que R Studio es la interfaz amigable que permite ejecutar código de R."
  },
  {
    "objectID": "syllabus.html#aviso-de-servicio-público",
    "href": "syllabus.html#aviso-de-servicio-público",
    "title": "Syllabus",
    "section": "Aviso de servicio público",
    "text": "Aviso de servicio público\nSi ya has usado R previamente, este curso será muy fácil para ti. Si no lo has usado nunca, aprender R puede que sea un poco menos fácil, pero prometo que solo al inicio. Como todo nuevo idioma comenzarás a ganar fluidez conforme hables más ‘R-ñol’: la práctica hace al maestro. Felizmenete, el dialecto tidy es muy fluido y fácil de entender y es por eso que lo hemos elegido.\nComo lo resalta Andrew Heiss en la web de su curso Program Evaluation, Hadley Wickham, científico de datos creador de tidyverse y fundador de RStudio una vez dijo:\n\nCuando comienzas a programar, es fácil frustrarte mucho y pensar: “Oh, soy yo, soy realmente estúpido” o “No estoy hecho para programar”. Pero, ese no es el caso en absoluto. Todo el mundo se frustra. Todavía me frustro ocasionalmente cuando escribo código R. Es solo una parte natural de la programación. Entonces, sucede a todos y se vuelve cada vez menos frecuente con el tiempo. No te culpes. Solo tómate un descanso, haz algo divertido y luego regresa e inténtalo de nuevo más tarde.\n\nIncluso analistas de datos con experiencia sufren cuando encuentran errores que se resiten a resolverse. Andrew Heiss cita un popular meme de un tweet para resumir este ubicuo problema:\n\nSi te toma demasiado tiempo pensar infructuosamente, mejor tómate un descanso, conversa con tus compañeros de clase, consúltame por correo, programa una reunión virtual, entre otras opciones.\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlison Horst: Gator error"
  },
  {
    "objectID": "syllabus.html#público-objetivo",
    "href": "syllabus.html#público-objetivo",
    "title": "Syllabus",
    "section": "Público objetivo",
    "text": "Público objetivo\nEste curso está dirigido a estudiantes, profesionales y personas de diversas disciplinas que trabajan en áreas relacionadas con las Ciencias de la Salud, con conocimientos básicos de manejo de datos en R y con interés en realizar análisis descriptivo y/o inferencial.\nYa sea que hagas investigación biomédica, seas funcionario de una institución pública o trabajador en el sector privado, te dediques a la gestión o brindes soporte técnico especializado, si los datos en salud forman parte de tu rutina diaria, ¡este curso es para ti!."
  },
  {
    "objectID": "syllabus.html#materiales-del-curso",
    "href": "syllabus.html#materiales-del-curso",
    "title": "Syllabus",
    "section": "Materiales del curso",
    "text": "Materiales del curso\nLa mayoría de los materiales en este curso son libres.\n\nLibros\nHay algunos libros que usaremos constantemente para este curso. Todos están disponibles digitalmente y son libres. La lista a continuación:\nLibros de bioestadística o ciencia de datos en salud\n\nBatra, Neale, et al. The Epidemiologist R Handbook. 2021. https://epirhandbook.com/en/index.html (Libre como versión HTML!)\nBrad Cannell, Melvin Livingston. R for Epidemiology.https://www.r4epi.com/(Libre como versión HTML!)\nEwen Harrison and Riinu Pius. R for Health Data Science. 2021. https://argoshare.is.ed.ac.uk/healthyr_book/(Libre como versión HTML!, pero hay una versión impresa por $63.96 en Routledge)\nPeter D.R. Higgins. Reproducible Medical Research with R. 2022.https://bookdown.org/pdr_higgins/rmrwr/(Libre como versión HTML!)\nKamarul Imran, Wan Nor Arifin, Tengku Muhammad Hanis Tengku Mukhtar. Data Analysis in Medicine and Health using R. 2022. https://bookdown.org/drki_musa/dataanalysis/ (Libre como versión HTML!)\nJames Brophy. (Mostly Clinical) Epidemiology with R. 2021. https://bookdown.org/jbrophy115/bookdown-clinepi/(Libre como versión HTML!)\n\nLibros de ciencia de datos o estadística general\n\nChester Ismay and Albert Y. Kim. Statistical Inference via Data Science: A ModernDive into R and the Tidyverse! 2022 https://moderndive.com/index.html(Libre como versión HTML!, pero hay una versión impresa por $57.25 en Amazon)\nHadley Wickham & Garrett Grolemund. R for Data Sciencehttps://r4ds.had.co.nz/index.html(Libre como versión HTML!, pero hay una versión impresa por $18.99 a 46.74 en Amazon)\n\n\n\nArtículos, capítulos de libro, y otros materiales\nOcasionalmente también habrá artículos y videos adicionales para leer y mirar. Cuando esto suceda, los enlaces a estos otros recursos se incluirán en la página de lectura de esa semana.\n\n\nAyuda en línea\nLa Ciencia de Datos en Salud, la Bioestadística y la Programación pueden no ser tan sencillas. Las computadoras no piensan y errores sutiles pueden causar horas de estancamiento incluso si ya cuentan con mucha experiencia.\nPor tal motivo, hemos habilitado dos canales para que puedan hacer sus consultas las 24 horas del día, los 7 días de la semana:\n\n Canal de Discord: Pueden hacer sus preguntas por este canal todo el tiempo que gusten. Este canal permanecerá abierto siempre, incluso muchos años después de terminado el curso, por lo que pueden volver a este cada vez que tengan consultas en el futuro.\n Grupo de Whatssap: También pueden consultar por este canal. Sin embargo, para reducir el Spam y poder tener un mejor registro de las consultas, sugerimos que usen preferentemente el acnal de Discord.\n\nSupervisaré discord y whatssap regularmente y responderé rápidamente. Sin embargo, puede que por mi ajetreada vida laboral y familiar, no pueda responder inmediatamente. Prometo que trataré de hacerlo dentro de las primeras 24 horas. Haga preguntas sobre las clases o problem sets. Es probable que tenga preguntas similares a las de sus compañeros y que también pueda responder las preguntas de otras personas.\n\n\n\n\n\n\nNota importante\n\n\n\nAmbos canales están reservados solo para alumnos del curso.\n\n\nEs posible que nosotros no podamos resolver todas sus dudas. Las Ciencias de Datos pueden llegar a ser realmente complejas, por lo que un poco de ayuda externa más experta podría ser necesaria.\nFelizmente, existe una inmensa comunidad en línea de usuarios de R, quienes continuamente intercambian soluciones. Es muy probable que tu problema ya haya sido resuelto antes y que su solución se encuentre en la web, solo tienes que saber dónde buscarla.\nDos de los más importantes sitios donde puedes buscar soluciones a tus problemas o consultar directamente son StackOverflow (un foro de preguntas y respuestas con cientos de miles de respuestas a todo tipo de preguntas sobre programación) y RStudio Community (un foro diseñado específicamente para personas que usan RStudio y tidyverse).\nSi usa Twitter, publique preguntas y contenido relacionados con R usnado #rstats. La comunidad allí es excepcionalmente generosa y servicial.\nBuscar soluciones en Google también es una buena opción, pero es un poco truculento si no sabes cómo hacerlo. Es mejor buscar en inglés, aunque también abunda información en español. Unos ejemplos de cómo buscar en Google podrían ser:\n\npropensity score matching r\n\no, si Google no reconoce a la letra r como el programa estadístico (¡pasa a veces!), puedes usar:\n\npropensity score matching rstats\n\nPor último, si sus consultas son especializadas en Ciencia de datos en Salud o Bioestadística, es probable que los foros mencionados no sean de ayuda. El foro Dathamethods es una buena plataforma para hacer este tipo de consultas. Esta plataforma es liderada por bioestadísticos y científicos de datos com amplia trayectoria en investigación clínico-epidemiológica. Frank Harrell, Bioestadístico asesor de la FDA, reconocido ‘trialista’ y experto en predicción clínica, es quien lidera esta plataforma y ha juntado una buena comunidad de bioestadísticos y científicos de datos siniors. Sugerimos se creen una cuenta y usen esta plataforma más a menudo.\nSi usas twitter, puedes consultar utilizando el hastagg #epitwitter, #MedStats. También puede ser de gran ayuda uniter al grupo de twitter Medical statistics: ‘A non comprhensive list of medical statisticians and methodologist’ creada por (MaartenvSmeden?)."
  },
  {
    "objectID": "syllabus.html#estructura-del-curso",
    "href": "syllabus.html#estructura-del-curso",
    "title": "Syllabus",
    "section": "Estructura del curso",
    "text": "Estructura del curso\nEste curso será completamente virtual y principalmente asincrónico. Sin embargo, existirá un componente sincrónico opcional. Las videoclases serán compartidas todos los sábados para que ustedes puedan verlas en cualquier momento y en el horario que deseen. Opcionalmente, ustedes pueden reunire conmigo en alguna de las dos horas semanales que destinaremos de conexión sincrónica. Me conectaré al meet los martes y jueves de 7 a 8 pm para absolver cualquier duda que tengan, resolver ejercicios de R juntos o conversar sobre la forma en que lo aprendido en el curso se podría aplicar a sus investigaciones."
  },
  {
    "objectID": "syllabus.html#asistencia-participación-y-calificación",
    "href": "syllabus.html#asistencia-participación-y-calificación",
    "title": "Syllabus",
    "section": "Asistencia, participación y calificación",
    "text": "Asistencia, participación y calificación\nSe espera que los participantes tomen las lecciones grabadas de manera asincrónica y desarrollen los problem-set encargados. Las reuniones semanales sincrónicas pueden ser usadas para revisar las preguntas de los problem-set planteados.\nUsted puede optar por dos tipos de constancias:\n\n\n\n\n\n\nConstancia de aprobado\n\n\n\nCuando el participante haya aprobado satisfactoriamente con nota mínima 14 (catorce) el curso.\n\n\n\n\n\n\n\n\nConstancia de participación o asistencia\n\n\n\nCuando no tenga nota aprobatoria habiendo asistido o cumplido con las actividades programadas según lo establecido en el syllabus.\n\n\nEn total habrán 7 problem set, los cuales son de carácter individual y permitirán calificar para la Constancia de aprobado."
  },
  {
    "objectID": "syllabus.html#políticas-del-curso",
    "href": "syllabus.html#políticas-del-curso",
    "title": "Syllabus",
    "section": "Políticas del curso",
    "text": "Políticas del curso\nEl presente curso tiene el siguiente código de honor:\n\nSus respuestas a tareas, cuestionarios y exámenes deben ser su propio trabajo (excepto las tareas que permitan explícitamente la colaboración).\nNo puede compartir sus soluciones a la tarea, cuestionarios o exámenes con nadie más a menos que lo permita explícitamente las instrucciones de la actividad. Esto incluye todo lo escrito por usted, así como cualquier solución oficial proporcionada por el personal del curso.\nNo puede participar en ninguna otra actividad que deshonestamente mejore sus resultados o deshonestamente mejore o perjudique los resultados de otros.\n\nAsimismo, si bien el syllabus refleja el plan del curso, algunas desviaciones a este podrían tornarse necesarias para alcanzar las metas propuestas.\n\nEntrega retrasada\nTiene hasta una semana adicional de tolerancia para realizar una entrega tardía. Esta entrega tardía no será penalizada, sin embargo, debe ser una alerta para que Ud. note que no está avanzando al ritmo sugerido durante el curso. Puede aprovechar las reuniones sincrónicas para revisar el borrador de la tarea con mi persona y ‘desestancarse’ si este es el caso.\nLuego de la semana de tolerancia, perderá 1 punto por cada día de retraso en al entrega del problema set."
  },
  {
    "objectID": "syllabus.html#tareas-y-calificaciones",
    "href": "syllabus.html#tareas-y-calificaciones",
    "title": "Syllabus",
    "section": "Tareas y calificaciones",
    "text": "Tareas y calificaciones\nPuedes encontrar las descripciones de todos los problem sets en la página de tareas.\n\n\n\n\n\n\n\n\n\nTarea\nPuntos\nPorcentaje\n\n\n\n\nProblem sets (7 × 30)\n140\n80%\n\n\nVer videoclases\n35\n20%\n\n\nTotal\n175\n—\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNota\nRango\nNota\nRango\n\n\n\n\nA\n93–100%\nC\n73–76%\n\n\nA−\n90–92%\nC−\n70–72%\n\n\nB+\n87–89%\nD+\n67–69%\n\n\nB\n83–86%\nD\n63–66%\n\n\nB−\n80–82%\nD−\n60–62%\n\n\nC+\n77–79%\nF\n< 60%"
  }
]